import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional
from scipy.signal import find_peaks, peak_widths
from MPSPlots.styles import mps
from FlowCyPy import ureg
from FlowCyPy.utils import find_matching_indices
from FlowCyPy.dataset import DataSet
import warnings
import logging


class PeakAnalyzer:
    """
    A class to analyze pulse signals generated by a flow cytometer, extracting features
    such as pulse height, width, and area from the signal.

    Attributes
    ----------
    detectors : List[object]
        List of detector objects for analysis.

    Methods
    -------
    run_analysis(compute_peak_area=True, height_threshold=None):
        Detects and extracts features from signals.
    get_coincidence_dataset(coincidence_margin=0.1):
        Returns datasets where peak times from different detectors match within a given margin.
    find_peaks(detector, peak_area=True, height_threshold=None):
        Detects significant peaks and calculates their features.
    display_features():
        Displays detected features in tabular format.
    plot():
        Plots signals along with detected peaks.
    """

    def __init__(self, *detectors: object) -> None:
        """
        Initializes the PeakAnalyzer with a list of detectors.

        Parameters
        ----------
        detectors : List[object]
            A list of detector objects that contain time and signal data.
        """
        if len(detectors) != 2:
            raise ValueError("PeakAnalyzer currently supports exactly two detectors.")
        self.detectors = detectors
        self.datasets = []

    def run_analysis(self, compute_peak_area: bool = False, height_threshold: float = None) -> None:
        """
        Runs the peak analysis on all detectors and extracts features like heights, widths, and areas.

        Parameters
        ----------
        compute_peak_area : bool, optional
            Whether to compute the area under the peaks, by default True.
        height_threshold : float, optional
            Threshold for peak detection, by default None.
        """
        for detector in self.detectors:
            time, heights, widths, area = self.find_peaks(detector, compute_peak_area, height_threshold)
            dataset = DataSet(time=time, height=heights, width=widths, area=area)
            dataset.detector = detector
            self.datasets.append(dataset)

            logging.info(f"Peak analyzer has detected {dataset.height.size} events.")

    def get_coincidence_dataset(self, coincidence_margin: float = 0.1) -> List[DataSet]:
        """
        Finds peaks that coincide between detectors within a margin and returns the corresponding datasets.

        Parameters
        ----------
        coincidence_margin : float
            Time margin within which peaks are considered coincident, in seconds.

        Returns
        -------
        List[DataSet]
            A list of datasets with coincident peaks.
        """
        matching_index = find_matching_indices(
            array_0=self.datasets[0].time,
            array_1=self.datasets[1].time,
            margin=coincidence_margin * ureg.second
        )

        coincidence_datasets = []
        for idx, dataset in enumerate(self.datasets):
            c_dataset = DataSet(
                time=dataset.time[matching_index[:, idx]],
                height=dataset.height[matching_index[:, idx]],
                width=dataset.width[matching_index[:, idx]],
                area=dataset.area[matching_index[:, idx]] if dataset.area is not None else None
            )

            c_dataset.detector = dataset.detector

            coincidence_datasets.append(c_dataset)

        n_coincidences = len(coincidence_datasets[0].time)
        n_events_detector_0 = len(self.datasets[0].time)
        n_events_detector_1 = len(self.datasets[1].time)

        if n_coincidences == 0:
            warnings.warn("No coincidence measurements found.")

        logging.info(f"Peak analyzer has detected {n_coincidences} coincidence events.")

        if (n_coincidences > n_events_detector_0) or (n_coincidences > n_events_detector_1):
            warnings.warn(
                "The number of coincidences exceeds the number of events in one or both detectors. "
                "This may indicate that the time detection margin is too large."
            )

        return coincidence_datasets

    def find_peaks(self, detector: object, peak_area: bool = True, height_threshold: float = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:
        """
        Detects peaks in the signal from a given detector and calculates their features.

        Parameters
        ----------
        detector : object
            Detector object containing the signal and time.
        peak_area : bool, optional
            If True, computes the area under each peak.
        height_threshold : float, optional
            The minimum height required for a peak to be considered significant.

        Returns
        -------
        Tuple[np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]
            Times, heights, widths, and optionally areas of detected peaks.
        """
        peak_indices, _ = find_peaks(detector.signal.magnitude, height=height_threshold)
        peak_times = peak_indices * detector.dt
        widths = peak_widths(detector.signal.magnitude, peak_indices, rel_height=0.5)[0] * detector.dt
        heights = detector.signal[peak_indices]

        if peak_area:
            start_idx = np.maximum(0, (peak_indices - widths / (2 * detector.dt)).astype(int))
            end_idx = np.minimum(len(detector.signal), (peak_indices + widths / (2 * detector.dt)).astype(int))

            areas = np.array([
                np.trapz(detector.signal.magnitude[start:end], detector.time.magnitude[start:end])
                for start, end in zip(start_idx.magnitude, end_idx.magnitude)
            ]) * ureg.volt * ureg.second

            return peak_times, heights, widths, areas

        return peak_times, heights, widths, None

    def display_features(self) -> None:
        """
        Displays extracted peak features for all datasets in a tabular format.
        """
        for i, dataset in enumerate(self.datasets):
            print(f"\nFeatures for Dataset {i + 1}:")
            dataset.print_properties()  # Reuse the print_properties method from DataSet


    def plot(self) -> None:
        """
        Plots the signal with detected peaks and widths at half-maximum, if available.
        """
        with plt.style.context(mps):
            fig, axes = plt.subplots(
                nrows=len(self.detectors),
                figsize=(10, 3 * len(self.detectors)),
                sharex=True
            )

            for ax, detector, dataset in zip(axes, self.detectors, self.datasets):
                ax.plot(detector.time.magnitude, detector.signal.magnitude, label='Signal')
                ax.vlines(dataset.time.magnitude, ymin=0, ymax=dataset.height.magnitude, color='r', label='Peaks')
                dataset._add_to_ax(ax, detector.time, detector.signal)

                handles, labels = ax.get_legend_handles_labels()
                by_label = dict(zip(labels, handles))
                ax.legend(by_label.values(), by_label.keys())
                ax.set_ylabel(f'Signal [{detector.name}]')

            axes[-1].set_xlabel('Time [s]')
            plt.show()

    def to_dataframe(self) -> pd.DataFrame:
        """
        Extracts all the data from the datasets into a pandas DataFrame.

        Returns
        -------
        pd.DataFrame
            A DataFrame containing time, height, width, and area (if available) for each dataset.
            The DataFrame includes columns to identify which detector the data belongs to.
        """
        data_frames = []
        for i, dataset in enumerate(self.datasets):
            # Create a dictionary for each dataset
            data_dict = {
                'Time': dataset.time.magnitude,
                'Height': dataset.height.magnitude,
                'Width': dataset.width.magnitude,
                'Area': dataset.area.magnitude if dataset.area is not None else None,
                'Detector': f'Detector_{i + 1}'  # Add a column to identify the detector
            }

            # Convert the dictionary to a pandas DataFrame
            df = pd.DataFrame(data_dict)
            data_frames.append(df)

        # Concatenate all the DataFrames into one
        combined_df = pd.concat(data_frames, ignore_index=True)

        return combined_df