# 配置文件介绍

- 当调用 **PrecisionDebugger** 接口执行 dump 或其他操作时，需要使用 [config.json](../config.json) 文件；当未指定 config.json 时，将使用默认配置。
- msprobe 成功安装后，config.json 一般位于如下目录：
```
/home/***/miniconda3/envs/***/lib/python3.8/site-packages/msprobe/
```

## 1 参数介绍

### 1.1 通用配置

| 参数名    | 解释    | 是否必选 |
| ----------------- | ---------------- | -------- |
| task              | dump 的任务类型，str 类型。可取值，<br/>  "statistics"：仅 dump API 统计信息，默认值；<br/> "tensor"：dump API 统计信息和完全复刻整网的 API 运行情况的真实数据；<br/> "run_ut"：精度预检，仅 PyTorch 场景支持。<br/> "overflow_check"：溢出检测，仅 PyTorch 和 MindSpore 静态图场景支持；<br/>  "free_benchmark"：无标杆比对；<br/>    根据 task 参数取值的不同，可以配置不同场景参数，详见：<br/>[1.2 task 配置为 statistics](#12-task-配置为-statistics)，<br/>[1.3 task 配置为 tensor](#13-task-配置为-tensor)，<br/>[1.4 task 配置为 run_ut](#14-task-配置为-run_ut)，<br/>[1.5 task 配置为 overflow_check](#15-task-配置为-overflow_check)，<br/>[1.6 task 配置为 free_benchmark](#16-task-配置为-free_benchmark)。 <br/>  **配置示例**："task": "tensor"。  | 否       |
| dump_path         | 设置 dump 数据目录路径，str 类型。<br/>  **配置示例**："dump_path": "./dump_path"。MindSpore 场景仅支持绝对路径。 | 是       |
| rank              | 指定对某张卡上的数据进行 dump，list[int] 类型，默认未配置（表示 dump 所有卡的数据），应配置为 ≥0 的整数，且须配置实际可用的 Rank ID。<br/>  <hr>PyTorch 场景：Rank ID 从 0 开始计数，最大取值为所有节点可用卡总数-1，若所配置的值大于实际训练所运行的卡的 Rank ID，则 dump 数据为空，比如当前环境 Rank ID 为 0 到 7，实际训练运行 0 到 3 卡，此时若配置 Rank ID 为 4 或不存在的 10 等其他值，dump 数据为空。<br/>  **配置示例**："rank": [1]。<hr> MindSpore 场景：所有节点的 Rank ID 均从 0 开始计数，最大取值为每个节点可用卡总数-1，config.json 配置一次 rank 参数对所有节点同时生效。<br/>  **配置示例**："rank": [1]。 | 否       |
| step              | 指定 dump 某个 step 的数据，list[int] 类型。默认未配置，表示 dump 所有 step 数据。dump 特定 step 时，须指定为训练脚本中存在的 step。step 为 list 格式，可配置逐个 step。<br/>  **配置示例**："step": [0,1,2]。 | 否       |
| level             | dump 级别，str 类型，根据不同级别 dump 不同数据。可取值，<br/>"L0"：dump 模块级精度数据，仅 PyTorch 与 MindSpore 动态图场景支持，使用背景详见 [1.1.1 模块级精度数据 dump 说明](#111-模块级精度数据-dump-说明)；<br/>"L1"：dump API 级精度数据，默认值，仅 PyTorch 与 MindSpore 动态图场景支持；<br/>"L2"：dump kernel 级精度数据，PyTorch场景下须配置 acl_config 参数；<br/>"mix"：dump module 模块级和 API 级精度数据，即"L0"+"L1"，仅 PyTorch 场景支持。<br/>  **配置示例**："level": "L1"。 | 否 |
| acl_config        | kernel dump 的配置文件，str 类型。level 取"L2"时，该参数必要；level 为其他值时，该参数不选。<br/> **配置示例**：acl_config="./acl_config.json"。具体配置见[ acl_config 示例](./04.acl_config_examples.md)。 | 否       |
| seed              | 随机种子数，int 类型，默认值为：1234，仅 PyTorch 场景支持。通过固定随机数保证模型的输入或输出一致，可固定的随机数详见 [1.1.2 固定随机数范围（仅 PyTorch 场景支持）](#112-固定随机数范围仅-pytorch-场景支持)。<br/>  **配置示例**："seed": 1234。 | 否       |
| is_deterministic  | 确定性计算模式，bool 类型，仅 PyTorch 场景支持。可取值 true（开启）或 false（关闭），默认关闭。<br/>  即使在相同的硬件和输入下，API 多次执行的结果也可能不同，开启确定性计算是为了保证在相同的硬件和输入下，API 多次执行的结果相同。<br/>确定性计算会导致 API 执行性能降低，建议在发现模型多次执行结果不同的情况下开启。<br/> rnn 类算子、ReduceSum、ReduceMean 等算子可能与确定性计算存在冲突，若开启确定性计算后多次执行的结果不相同，则考虑存在这些算子。<br/>  **配置示例**："is_deterministic": true。<br/>  | 否       |
| enable_dataloader | 自动控制开关，bool 类型，仅 PyTorch 场景支持。可取值 true（开启）或 false（关闭），默认为 false。配置为 True 后自动识别 step 参数指定的迭代，并在该迭代执行完成后退出训练，此时 start、stop 和 step 函数可不配置，开启该开关要求训练脚本是通过 torch.utils.data.dataloader 方式加载数据。仅支持 PyTorch 单卡训练使用，分布式训练场景下存在数据 dump 不全问题，**下个版本即将废弃该功能**。 | 否       |

#### 1.1.1 模块级精度数据 dump 说明

仅 PyTorch 与 MindSpore 动态图场景支持。

大模型场景下，通常不是简单的利用自动迁移能力实现从 GPU 到 NPU 的训练脚本迁移，而是会对 NPU 网络进行一系列针对性的适配，因此，常常会造成迁移后的 NPU 模型存在部分子结构不能与 GPU 原始模型完全对应。模型结构不一致导致 API 调用类型及数量不一致，若直接按照 API 粒度进行精度数据 dump 和比对，则无法完全比对所有的 API。

本小节介绍的功能是对模型中的大粒度模块进行数据 dump，使其比对时，对于无法以 API 粒度比对的模块可以直接以模块粒度进行比对。

模块指的是继承 nn.Module 类（PyTorch场景）或 nn.Cell 类（MindSpore场景）的子类，通常情况下这类模块就是一个小模型，可以被视为一个整体，dump 数据时以模块为粒度进行 dump。

#### 1.1.2 固定随机数范围（仅 PyTorch 场景支持）

seed_all 函数可固定随机数的范围如下表。

| API                                      | 固定随机数                  |
| ---------------------------------------- | --------------------------- |
| os.environ['PYTHONHASHSEED'] = str(seed) | 禁止 Python 中的 hash 随机化 |
| random.seed(seed)                        | 设置 random 随机生成器的种子  |
| np.random.seed(seed)                     | 设置 numpy 中随机生成器的种子 |
| torch.manual_seed(seed)                  | 设置当前 CPU 的随机种子       |
| torch.cuda.manual_seed(seed)             | 设置当前 GPU 的随机种子       |
| torch.cuda.manual_seed_all(seed)         | 设置所有 GPU 的随机种子       |
| torch_npu.npu.manual_seed(seed)          | 设置当前 NPU 的随机种子       |
| torch_npu.npu.manual_seed_all(seed)      | 设置所有 NPU 的随机种子       |
| torch.backends.cudnn.enable=False        | 关闭 cuDNN                   |
| torch.backends.cudnn.benchmark=False     | cuDNN 确定性地选择算法       |
| torch.backends.cudnn.deterministic=True  | cuDNN 仅使用确定性的卷积算法 |

需要保证 CPU 或 GPU 以及 NPU 的模型输入完全一致，dump 数据的比对才有意义，seed_all 并不能保证模型输入完全一致，如下表所示场景需要保证输入的一致性。

| 场景            | 固定方法      |
| --------------- | ------------- |
| 数据集的 shuffle | 关闭 shuffle。 |
| dropout         | 关闭 dropout。 |

关闭 shuffle 示例：

```python
train_loader = torch.utils.data.DataLoader(
train_dataset,
batch_size = batch_size,
shuffle = False,
num_workers = num_workers
)
```

关闭 dropout：

在使用 `from msprobe.pytorch import PrecisionDebugger` 后，工具会自动将 `torch.nn.functional.dropout`、`torch.nn.functional.dropout2d`、`torch.nn.functional.dropout3d`、`torch.nn.Dropout`、`torch.nn.Dropout2d`、`torch.nn.Dropout3d` 的接口参数 p 置为0。

### 1.2 task 配置为 statistics

| 参数名       | 解释               | 是否必选 |
| ------------ | ------------------- | -------- |
| scope        | PyTorch 和 MindSpore 动态图场景 dump 范围，list[str] 类型，默认未配置（list 也未配置时表示 dump 所有 API 的数据）。该参数在 [ ] 内配置两个模块名或 API 名，用于锁定区间，dump 该范围内的数据。<br/>**配置示例**："scope": ["MyModuleOP1", "MyModuleOP2"]。与 level 参数取值相关，level 为 L0 和 mix 级别时，可配置模块名；level 为 L1 级别时，可配置 API 名。MindSpore 动态图场景当前仅支持配置为 API 名。  | 否       |
| list         | 自定义 dump 范围，list[str] 类型，默认未配置（scope 也未配置时表示 dump 所有 API 的数据）。包含如下配置方法：<br>        PyTorch 和 MindSpore 动态图场景配置具体的 API 全称，dump 该 API 数据。<br/>**配置示例**："list": ["Tensor.permute.1.forward", "Tensor.transpose.2.forward", "Torch.relu.3.backward"]。<br/>  <hr>      PyTorch 和 MindSpore 动态图场景指定某一类 API，dump 某一类的 API 级别输入输出数据。<br/>**配置示例**："list": ["relu"]。<hr> MindSpore 静态图场景配置 kernel_name，可以是算子的名称列表，也可以指定算子类型（"level": "L2"时不支持），还可以配置算子名称的正则表达式（当字符串符合“name-regex(xxx)”格式时，后台则会将其作为正则表达式。例如，“name-regex(Default/.+)”可匹配算子名称以“Default/”开头的所有算子）。 | 否      |
| data_mode    | dump 数据过滤，str 类型。<br/><hr>PyTorch 场景：支持"all"、"forward"、"backward"、"input"和"output"，表示仅保存 dump 的数据中文件名包含"forward"、"backward"、"input"和"output"的前向、反向、输入或输出的 dump 文件。<br/> **配置示例**："data_mode": ["all"]。 <hr>MindSpore 场景：仅支持"all"、"input"和"output"参数，且各参数只能单独配置，不支持自由组合。<br/>**配置示例**："data_mode": ["backward"] 或 "data_mode": ["forward", "backward"]。默认为["all"]，即保存所有 dump 的数据。除了 all 参数只能单独配置外，其他参数可以自由组合。 | 否       |
| summary_mode | 控制 dump 文件输出的模式，str 类型，仅 PyTorch 场景支持，可取值，<br/> md5：dump 输出包含 md5 值以及 API 统计信息的 dump.json 文件，用于验证数据的完整性；<br/> statistics：dump 仅输出包含 API 统计信息的 dump.json 文件，默认值。<br/> **配置示例**："summary_mode": "md5"。 | 否       |

### 1.3 task 配置为 tensor

| 参数名         | 解释         | 是否必选 |
| -------------- | ---------------------- | -------- |
| scope          | 与[ 1.2 task 配置为 statistics ](#12-task-配置为-statistics)中的解释相同。 | 否       |
| list           | 与[ 1.2 task 配置为 statistics ](#12-task-配置为-statistics)中的解释相同。另外，<br/> PyTorch 和 MindSpore 动态图场景配置 kernel_api，dump 前向和反向 API 的kernel_api 级别数据，其中 dump 反向 API 时需要配置 **backward_input** 参数。<br/>**前向 API 配置示例**："list": ["Tensor.permute.1.forward"]；<br/>**反向 API 配置示例**："list": ["Tensor.permute.1.forward"], "backward.input": ["./npu_dump/step0/rank0/Functional.conv2d.1.backward.input.0.pt"]。<br/> | 否       |
| backward_input | 该输入文件为首次运行训练 dump 得到反向 API 输入的 dump 文件，str 类型，仅 PyTorch 场景支持，默认未配置。例如若需要 dump Functional.conv2d.1 API 的反向过程的输入输出，则需要在 dump 目录下查找命名包含 Functional.conv2d.1、backward 和 input 字段的 dump 文件。<br/>**配置示例**："backward_input": ["./npu_dump/step0/rank0/Functional.conv2d.1.backward.input.0.pt"] | 否       |
| data_mode      | 与[ 1.2 task 配置为 statistics ](#12-task-配置为-statistics)中的解释相同 | 否       |
| file_format    | MindSpore 静态图场景 tensor 数据的保存格式，str 类型，可取值，<br/> "bin"：dump 的 tensor 文件为二进制格式，"level": "L1" 时不支持；<br/>"npy"：dump 的 tensor 文件后缀为 .npy，默认值。 | 否       |
| online_run_ut<sup>a<sup/>  | 在线预检模式开关，bool 类型，可取值 true（开启）、false（关闭），默认未配置，表示关闭。配置为 true 表示开启在线预预检。| 否 |
| nfs_path<sup>a<sup/> | 在线预检模式共享存储目录路径，str 类型，用于 GPU 设备和 NPU 设备间进行通信。仅在 online_run_ut 字段配置为 true 时生效，未配置该参数后 host 和 port 不生效。 | 否 |
| host<sup>a<sup/> | 在线预检模式局域网场景信息接收端 IP，str 类型，用于 GPU 设备和 NPU 设备间进行通信，NPU 侧须配置为 GPU 侧的局域网 IP 地址。仅在 online_run_ut 字段配置为 true 时生效，局域网场景时，不能配置 nfs_path 参数，否则局域网场景不生效。 | 否 |
| port<sup>a<sup/> | 在线预检模式局域网场景信息接收端端口号，int 类型，用于 GPU 设备和 NPU 设备间进行通信，NPU 侧须配置为 GPU 侧的端口号。仅在 online_run_ut 字段配置为 true 时生效，局域网场景时，不能配置 nfs_path 参数，否则局域网场景不生效。| 否 |

**a**：online_run_ut、nfs_path、host、port 等字段仅在线预检场景 NPU 机器生效。

### 1.4 task 配置为 run_ut

| 参数名称        | 解释                   | 是否必选 |
| --------------- | ------------------------ | ------------ |
| white_list<sup>a</sup>      | API dump 白名单，仅对指定的 API 进行 dump。<br/>**配置示例**："white_list": ["conv1d", "conv2d"]。默认未配置白名单，即 dump 全量 API 数据。 | 否       |
| black_list<sup>a</sup>      | API dump 黑名单，被指定的 API 不进行 dump。<br/>**配置示例**："black_list": ["conv1d", "conv2d"]。默认未配置黑名单，即 dump 全量 API 数据。 | 否       |
| error_data_path | 配置保存精度未达标的 API 输入输出数据路径，默认为当前路径。<br/>**配置示例**："error_data_path": "./"。 | 否       |
| is_online<sup>b</sup>       | 在线预检模式开关，bool 类型，可取值 true（开启）、false（关闭），默认关闭。 | 否 |
| nfs_path<sup>b</sup>        | 在线预检模式共享存储目录路径，str 类型，用于 GPU 设备和 NPU 设备间进行通信。配置该参数后 host 和 port 不生效，仅在 is_online 字段配置为 true 时生效。 | 否    |
| host<sup>b</sup>            | 在线预检模式局域网场景信息接收端 IP，str 类型，用于 GPU 设备和 NPU 设备间进行通信，GPU 侧配置为本机地址 127.0.0.1 或本机局域网 IP。局域网场景时，不能配置 nfs_path 参数，否则局域网场景不生效。仅在 is_online 字段配置为 true 时生效。 | 否 |
| port<sup>b</sup>            | 在线预检模式局域网场景信息接收端端口号，int 类型，用于 GPU 设备和 NPU 设备间进行通信，GPU 侧配置为本机可用端口。局域网场景时，不能配置 nfs_path 参数，否则局域网场景不生效。仅在 is_online 字段配置为 true 时生效。| 否 |
| rank_list<sup>b</sup>       | 指定在线预检的 Rank ID，默认值为 [0]，list[int] 类型，应配置为大于等于 0 的整数，且须根据实际卡的 Rank ID 配置，若所配置的值大于实际训练所运行的卡的 Rank ID，则在线预检输出数据为空。GPU 和 NPU 须配置一致。仅在 is_online 字段配置为 true 时生效。 | 否    |

**a**：white_list 和 black_list 同时配置时，二者配置的 API 名单若无交集，则白名单生效，若 API 名单存在交集，则白名单排除的部分以及交集的 API 不进行 dump。

**b**：is_online、nfs_path、host、port、rank_list 等字段仅在线预检场景 GPU 机器生效。

### 1.5 task 配置为 overflow_check

PyTorch 与 MindSpore 动态图场景下，"level"须为"L1"；MindSpore 静态图场景下，"level"须为"L2"。

| 参数名        | 解释                 | 是否必选 |
| ------------- | ---------------------- | -------- |
| overflow_nums | 最大溢出次数，int 类型，默认为 1，仅 PyTorch 与 MindSpore 动态图场景支持。表示第 N 次溢出后，不再进行溢出检测。过程中检测到溢出 API 对应的 输入输出 数据均 dump。<br/>**配置示例**："overflow_nums": 3。配置为 -1 时，表示持续检测溢出直到训练结束。 | 否       |
| check_mode    | MindSpore 静态图场景 kernel 级别的溢出检测，str 类型，可取值：<br/>"aicore"：开启 AI Core 的溢出检测；<br/>"atomic"：开启 Atomic 的溢出检测；<br/>"all"：开启 AI Core 和 Atomic 的溢出检测，默认值。<br/>**配置示例**："check_mode": "aicore"。 | 否       |

### 1.6 task 配置为 free_benchmark

仅 PyTorch 场景与 MindSpore 动态图场景支持，且"level"为"L1"。

- task 配置为 free_benchmark 时，开启**无标杆比对**，在 NPU 环境下通过对当前模型 API 的输入添加扰动因子，二次执行，将得到的输出与未添加扰动因子前的输出进行比对，从而**得出该模型中可能存在因迁移等变化导致精度降低的 API**。

- 无标杆比对优势在于省去了从 CPU/GPU 环境获取标杆数据的步骤，也省去了在 NPU 环境执行 dump 的操作，降低了精度比对的操作难度。

- 建议配置白名单（配置 scope 或 list）控制少量 API 进行无标杆比对，一次对过多 API 执行无标杆比对可能导致显存溢出或性能膨胀。

| 参数名       | 解释               | 是否必选 |
| ------------ | -------------- | -------- |
| scope        | 自定义检测 API 列表（仅 PyTorch 场景支持），list[str] 类型，默认值为空列表，当 list 也为空列表时，表示检测所有 API。需要在 [ ] 内配置具体 API 名（在 dump 的结果中查看）。<br/>**配置示例**："scope": ["Torch.matmul.0", "Tensor.pow.4"]。<br/>与 list 参数不能同时配置。 | 否       |
| list         | 自定义检测 API 类型或 API 名称，list[str] 类型，默认值为空列表，表示检测所有 API（PyTorch 场景下还需 scope 也为空列表）。<br><hr>        PyTorch 场景：指定某一类 API，对某一类的 API 进行无标杆比对。<br/>**配置示例**："list": ["relu"]。<br/> <hr>       MindSpore 场景：指定 API 名称，对列表中的 API 进行检测。<br/>**配置示例**："list": ["mindspore.mint.div", "mindspore.ops.bmm", "mindspore.Tensor.\_\_add\_\_"]。<br/>与 scope 参数不能同时配置。 | 否       |
| fuzz_device  | 标杆设备，str 类型。可取值，<br/>        "npu"：无标杆，通过添加扰动因子进行比对，默认值；<br/>        "cpu"：以 CPU 为标杆，pert_mode 须配置为"to_cpu"（仅 PyTorch 场景支持）。<br/>**配置示例**："fuzz_device": "cpu"。 | 否       |
| pert_mode    | 无标杆扰动因子，str 类型。可取值，<br/>  "improve_precision"：对输入做升精度，默认值；<br/>        "add_noise"：对输入增加噪声；<br/>        "no_change"：不加扰动直接二次执行；<br/>        "bit_noise"：输入的末位比特翻转；<br/>        "change_value"：输入的张量首尾值调换（仅 PyTorch 场景支持）；<br/>        "to_cpu"：在 CPU 等价执行（仅 PyTorch 场景支持）。<br/>**配置示例**："pert_mode": "improve_precision"。 | 否       |
| handler_type | 处理类型，可取值，<br/> "check"：进行无标杆比对检查，默认值；<br/> "fix"：将扰动后的 API 输出结果覆盖原始 API 输出结果，尝试将 Loss 曲线恢复正常，该模式下不支持预热 if_preheat。<br/> **配置示例**："handler_type": "fix"。 | 否       |
| fuzz_level   | 无标杆数据 dump 级别，即选择比对结果文件应输出的表头属性，当前仅支持取值为："L1"。输出结果详见 [1.6.1 无标杆比对数据存盘格式]()。 | 否       |
| fuzz_stage   | 前反向，选择对 API 前向或反向进行无标杆比对，可取值：<br/> "forward"：前向，默认值；<br/>  "backward"：反向。<br/>  **配置示例**："fuzz_stage": "backward"。 | 否       |
| if_preheat   | 预热功能（仅 PyTorch 场景支持），开启功能后工具可以根据每次迭代的输出调整精度算法的阈值，从而更准确地找出存在精度问题的 API，bool 类型。可取值：<br/>  true（开启）或 false（关闭），默认关闭。<br/>  **配置示例**："if_preheat": "true"。"handler_type": "fix"不支持预热。 | 否       |
| preheat_step | 开启预热的迭代数量（仅 PyTorch 场景支持），int 类型，默认值为 15。须配置 "if_preheat": "true"。 | 否       |
| max_sample   | 每个算子预热的采样次数的最大阈值（仅 PyTorch 场景支持），int 类型，默认值为 20。须配置 "if_preheat": "true"。 | 否       |

#### 1.6.1 无标杆比对数据存盘格式

无标杆比对在 dump_path 目录下输出结果文件 `free_benchmark.csv`，如下示例：

![free_benchmark](./img/free_benchmark.png)

| 字段         | 说明                                                         |
| ------------ | --------------------- |
| rank         | Rank ID，int 类型。                                           |
| pert_mode    | 扰动因子的类型，string 类型。                                 |
| stage        | 前向或反向，string 类型。                                     |
| step         | 迭代数，int 类型。                                            |
| api_name     | API 名称，string 类型。                                        |
| max_rel      | 输出对比最大相对误差，float 类型。                            |
| dtype        | 输入的 dtype，string 类型。                                    |
| shape        | 输入的 shape，tuple 类型。                                     |
| output_index | 如果输出为列表或元组，其中一个元素检测不一致，则会有该元素的 index，否则为空，int 类型。 |
