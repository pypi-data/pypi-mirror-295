# This file was auto-generated by Fern from our API Definition.

import typing
from .environment import GooeyEnvironment
import os
import httpx
from .core.api_error import ApiError
from .core.client_wrapper import SyncClientWrapper
from .copilot.client import CopilotClient
from .types.deforum_sd_page_request_animation_prompts_item import DeforumSdPageRequestAnimationPromptsItem
from .types.deforum_sd_page_request_functions_item import DeforumSdPageRequestFunctionsItem
from .types.deforum_sd_page_request_selected_model import DeforumSdPageRequestSelectedModel
from .types.run_settings import RunSettings
from .core.request_options import RequestOptions
from .types.deforum_sd_page_output import DeforumSdPageOutput
from .core.pydantic_utilities import parse_obj_as
from .errors.payment_required_error import PaymentRequiredError
from .types.generic_error_response import GenericErrorResponse
from .errors.unprocessable_entity_error import UnprocessableEntityError
from .types.http_validation_error import HttpValidationError
from .errors.too_many_requests_error import TooManyRequestsError
from json.decoder import JSONDecodeError
from .types.qr_code_request_functions_item import QrCodeRequestFunctionsItem
from . import core
from .types.qr_code_request_qr_code_vcard import QrCodeRequestQrCodeVcard
from .types.qr_code_request_image_prompt_controlnet_models_item import QrCodeRequestImagePromptControlnetModelsItem
from .types.qr_code_request_selected_model import QrCodeRequestSelectedModel
from .types.qr_code_request_selected_controlnet_model_item import QrCodeRequestSelectedControlnetModelItem
from .types.qr_code_request_scheduler import QrCodeRequestScheduler
from .types.qr_code_generator_page_output import QrCodeGeneratorPageOutput
from .types.related_qn_a_page_request_functions_item import RelatedQnAPageRequestFunctionsItem
from .types.related_qn_a_page_request_selected_model import RelatedQnAPageRequestSelectedModel
from .types.related_qn_a_page_request_embedding_model import RelatedQnAPageRequestEmbeddingModel
from .types.related_qn_a_page_request_response_format_type import RelatedQnAPageRequestResponseFormatType
from .types.serp_search_location import SerpSearchLocation
from .types.serp_search_type import SerpSearchType
from .types.related_qn_a_page_output import RelatedQnAPageOutput
from .types.seo_summary_page_request_selected_model import SeoSummaryPageRequestSelectedModel
from .types.seo_summary_page_request_response_format_type import SeoSummaryPageRequestResponseFormatType
from .types.seo_summary_page_output import SeoSummaryPageOutput
from .types.google_gpt_page_request_functions_item import GoogleGptPageRequestFunctionsItem
from .types.google_gpt_page_request_selected_model import GoogleGptPageRequestSelectedModel
from .types.google_gpt_page_request_embedding_model import GoogleGptPageRequestEmbeddingModel
from .types.google_gpt_page_request_response_format_type import GoogleGptPageRequestResponseFormatType
from .types.google_gpt_page_output import GoogleGptPageOutput
from .types.social_lookup_email_page_request_functions_item import SocialLookupEmailPageRequestFunctionsItem
from .types.social_lookup_email_page_request_selected_model import SocialLookupEmailPageRequestSelectedModel
from .types.social_lookup_email_page_request_response_format_type import SocialLookupEmailPageRequestResponseFormatType
from .types.social_lookup_email_page_output import SocialLookupEmailPageOutput
from .types.bulk_run_request_functions_item import BulkRunRequestFunctionsItem
from .types.bulk_runner_page_output import BulkRunnerPageOutput
from .types.bulk_eval_page_request_functions_item import BulkEvalPageRequestFunctionsItem
from .types.bulk_eval_page_request_eval_prompts_item import BulkEvalPageRequestEvalPromptsItem
from .types.bulk_eval_page_request_agg_functions_item import BulkEvalPageRequestAggFunctionsItem
from .types.bulk_eval_page_request_selected_model import BulkEvalPageRequestSelectedModel
from .types.bulk_eval_page_request_response_format_type import BulkEvalPageRequestResponseFormatType
from .types.bulk_eval_page_output import BulkEvalPageOutput
from .types.synthesize_data_request_functions_item import SynthesizeDataRequestFunctionsItem
from .types.synthesize_data_request_selected_asr_model import SynthesizeDataRequestSelectedAsrModel
from .types.synthesize_data_request_selected_model import SynthesizeDataRequestSelectedModel
from .types.synthesize_data_request_response_format_type import SynthesizeDataRequestResponseFormatType
from .types.doc_extract_page_output import DocExtractPageOutput
from .types.compare_llm_page_request_functions_item import CompareLlmPageRequestFunctionsItem
from .types.compare_llm_page_request_selected_models_item import CompareLlmPageRequestSelectedModelsItem
from .types.compare_llm_page_request_response_format_type import CompareLlmPageRequestResponseFormatType
from .types.compare_llm_page_output import CompareLlmPageOutput
from .types.doc_search_page_request_functions_item import DocSearchPageRequestFunctionsItem
from .types.doc_search_page_request_keyword_query import DocSearchPageRequestKeywordQuery
from .types.doc_search_page_request_embedding_model import DocSearchPageRequestEmbeddingModel
from .types.doc_search_page_request_selected_model import DocSearchPageRequestSelectedModel
from .types.doc_search_page_request_citation_style import DocSearchPageRequestCitationStyle
from .types.doc_search_page_request_response_format_type import DocSearchPageRequestResponseFormatType
from .types.doc_search_page_output import DocSearchPageOutput
from .types.smart_gpt_page_request_functions_item import SmartGptPageRequestFunctionsItem
from .types.smart_gpt_page_request_selected_model import SmartGptPageRequestSelectedModel
from .types.smart_gpt_page_request_response_format_type import SmartGptPageRequestResponseFormatType
from .types.smart_gpt_page_output import SmartGptPageOutput
from .types.doc_summary_request_functions_item import DocSummaryRequestFunctionsItem
from .types.doc_summary_request_selected_model import DocSummaryRequestSelectedModel
from .types.doc_summary_request_selected_asr_model import DocSummaryRequestSelectedAsrModel
from .types.doc_summary_request_response_format_type import DocSummaryRequestResponseFormatType
from .types.doc_summary_page_output import DocSummaryPageOutput
from .types.functions_page_output import FunctionsPageOutput
from .types.lipsync_request_functions_item import LipsyncRequestFunctionsItem
from .types.lipsync_request_sadtalker_settings import LipsyncRequestSadtalkerSettings
from .types.lipsync_request_selected_model import LipsyncRequestSelectedModel
from .types.lipsync_page_output import LipsyncPageOutput
from .types.lipsync_tts_request_functions_item import LipsyncTtsRequestFunctionsItem
from .types.lipsync_tts_request_tts_provider import LipsyncTtsRequestTtsProvider
from .types.lipsync_tts_request_openai_voice_name import LipsyncTtsRequestOpenaiVoiceName
from .types.lipsync_tts_request_openai_tts_model import LipsyncTtsRequestOpenaiTtsModel
from .types.lipsync_tts_request_sadtalker_settings import LipsyncTtsRequestSadtalkerSettings
from .types.lipsync_tts_request_selected_model import LipsyncTtsRequestSelectedModel
from .types.lipsync_tts_page_output import LipsyncTtsPageOutput
from .types.text_to_speech_page_request_functions_item import TextToSpeechPageRequestFunctionsItem
from .types.text_to_speech_page_request_tts_provider import TextToSpeechPageRequestTtsProvider
from .types.text_to_speech_page_request_openai_voice_name import TextToSpeechPageRequestOpenaiVoiceName
from .types.text_to_speech_page_request_openai_tts_model import TextToSpeechPageRequestOpenaiTtsModel
from .types.text_to_speech_page_output import TextToSpeechPageOutput
from .types.speech_recognition_request_functions_item import SpeechRecognitionRequestFunctionsItem
from .types.speech_recognition_request_selected_model import SpeechRecognitionRequestSelectedModel
from .types.speech_recognition_request_translation_model import SpeechRecognitionRequestTranslationModel
from .types.speech_recognition_request_output_format import SpeechRecognitionRequestOutputFormat
from .types.asr_page_output import AsrPageOutput
from .types.text2audio_page_request_functions_item import Text2AudioPageRequestFunctionsItem
from .types.text2audio_page_output import Text2AudioPageOutput
from .types.translate_request_functions_item import TranslateRequestFunctionsItem
from .types.translate_request_selected_model import TranslateRequestSelectedModel
from .types.translation_page_output import TranslationPageOutput
from .types.remix_image_request_functions_item import RemixImageRequestFunctionsItem
from .types.remix_image_request_selected_model import RemixImageRequestSelectedModel
from .types.remix_image_request_selected_controlnet_model import RemixImageRequestSelectedControlnetModel
from .types.img2img_page_output import Img2ImgPageOutput
from .types.compare_text2img_page_request_functions_item import CompareText2ImgPageRequestFunctionsItem
from .types.compare_text2img_page_request_selected_models_item import CompareText2ImgPageRequestSelectedModelsItem
from .types.compare_text2img_page_request_scheduler import CompareText2ImgPageRequestScheduler
from .types.compare_text2img_page_output import CompareText2ImgPageOutput
from .types.product_image_request_functions_item import ProductImageRequestFunctionsItem
from .types.product_image_request_selected_model import ProductImageRequestSelectedModel
from .types.object_inpainting_page_output import ObjectInpaintingPageOutput
from .types.portrait_request_functions_item import PortraitRequestFunctionsItem
from .types.portrait_request_selected_model import PortraitRequestSelectedModel
from .types.face_inpainting_page_output import FaceInpaintingPageOutput
from .types.email_face_inpainting_page_request_functions_item import EmailFaceInpaintingPageRequestFunctionsItem
from .types.email_face_inpainting_page_request_selected_model import EmailFaceInpaintingPageRequestSelectedModel
from .types.email_face_inpainting_page_output import EmailFaceInpaintingPageOutput
from .types.google_image_gen_page_request_functions_item import GoogleImageGenPageRequestFunctionsItem
from .types.google_image_gen_page_request_selected_model import GoogleImageGenPageRequestSelectedModel
from .types.google_image_gen_page_output import GoogleImageGenPageOutput
from .types.remove_background_request_functions_item import RemoveBackgroundRequestFunctionsItem
from .types.remove_background_request_selected_model import RemoveBackgroundRequestSelectedModel
from .types.image_segmentation_page_output import ImageSegmentationPageOutput
from .types.upscale_request_functions_item import UpscaleRequestFunctionsItem
from .types.upscale_request_selected_models_item import UpscaleRequestSelectedModelsItem
from .types.compare_upscaler_page_output import CompareUpscalerPageOutput
from .types.embeddings_page_request_functions_item import EmbeddingsPageRequestFunctionsItem
from .types.embeddings_page_request_selected_model import EmbeddingsPageRequestSelectedModel
from .types.embeddings_page_output import EmbeddingsPageOutput
from .types.related_qn_a_doc_page_request_functions_item import RelatedQnADocPageRequestFunctionsItem
from .types.related_qn_a_doc_page_request_keyword_query import RelatedQnADocPageRequestKeywordQuery
from .types.related_qn_a_doc_page_request_embedding_model import RelatedQnADocPageRequestEmbeddingModel
from .types.related_qn_a_doc_page_request_selected_model import RelatedQnADocPageRequestSelectedModel
from .types.related_qn_a_doc_page_request_citation_style import RelatedQnADocPageRequestCitationStyle
from .types.related_qn_a_doc_page_request_response_format_type import RelatedQnADocPageRequestResponseFormatType
from .types.related_qn_a_doc_page_output import RelatedQnADocPageOutput
from .types.balance_response import BalanceResponse
from .core.client_wrapper import AsyncClientWrapper
from .copilot.client import AsyncCopilotClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class Gooey:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : typing.Optional[str]
        The base url to use for requests from the client.

    environment : GooeyEnvironment
        The environment to use for requests from the client. from .environment import GooeyEnvironment



        Defaults to GooeyEnvironment.DEFAULT



    api_key : typing.Optional[typing.Union[str, typing.Callable[[], str]]]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.Client]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from gooey import Gooey

    client = Gooey(
        api_key="YOUR_API_KEY",
    )
    """

    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: GooeyEnvironment = GooeyEnvironment.DEFAULT,
        api_key: typing.Optional[typing.Union[str, typing.Callable[[], str]]] = os.getenv("GOOEY_API_KEY"),
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.Client] = None,
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        if api_key is None:
            raise ApiError(body="The client must be instantiated be either passing in api_key or setting GOOEY_API_KEY")
        self._client_wrapper = SyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            api_key=api_key,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.Client(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.Client(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.copilot = CopilotClient(client_wrapper=self._client_wrapper)

    def animate(
        self,
        *,
        animation_prompts: typing.Sequence[DeforumSdPageRequestAnimationPromptsItem],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[DeforumSdPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        max_frames: typing.Optional[int] = OMIT,
        selected_model: typing.Optional[DeforumSdPageRequestSelectedModel] = OMIT,
        animation_mode: typing.Optional[str] = OMIT,
        zoom: typing.Optional[str] = OMIT,
        translation_x: typing.Optional[str] = OMIT,
        translation_y: typing.Optional[str] = OMIT,
        rotation3d_x: typing.Optional[str] = OMIT,
        rotation3d_y: typing.Optional[str] = OMIT,
        rotation3d_z: typing.Optional[str] = OMIT,
        fps: typing.Optional[int] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeforumSdPageOutput:
        """
        Parameters
        ----------
        animation_prompts : typing.Sequence[DeforumSdPageRequestAnimationPromptsItem]

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[DeforumSdPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        max_frames : typing.Optional[int]

        selected_model : typing.Optional[DeforumSdPageRequestSelectedModel]

        animation_mode : typing.Optional[str]

        zoom : typing.Optional[str]

        translation_x : typing.Optional[str]

        translation_y : typing.Optional[str]

        rotation3d_x : typing.Optional[str]

        rotation3d_y : typing.Optional[str]

        rotation3d_z : typing.Optional[str]

        fps : typing.Optional[int]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeforumSdPageOutput
            Successful Response

        Examples
        --------
        from gooey import DeforumSdPageRequestAnimationPromptsItem, Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.animate(
            animation_prompts=[
                DeforumSdPageRequestAnimationPromptsItem(
                    frame="frame",
                    prompt="prompt",
                )
            ],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/DeforumSD/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "animation_prompts": animation_prompts,
                "max_frames": max_frames,
                "selected_model": selected_model,
                "animation_mode": animation_mode,
                "zoom": zoom,
                "translation_x": translation_x,
                "translation_y": translation_y,
                "rotation_3d_x": rotation3d_x,
                "rotation_3d_y": rotation3d_y,
                "rotation_3d_z": rotation3d_z,
                "fps": fps,
                "seed": seed,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DeforumSdPageOutput,
                    parse_obj_as(
                        type_=DeforumSdPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def qr_code(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[QrCodeRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        qr_code_data: typing.Optional[str] = OMIT,
        qr_code_input_image: typing.Optional[core.File] = OMIT,
        qr_code_vcard: typing.Optional[QrCodeRequestQrCodeVcard] = OMIT,
        qr_code_file: typing.Optional[core.File] = OMIT,
        use_url_shortener: typing.Optional[bool] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        image_prompt: typing.Optional[str] = OMIT,
        image_prompt_controlnet_models: typing.Optional[
            typing.List[QrCodeRequestImagePromptControlnetModelsItem]
        ] = OMIT,
        image_prompt_strength: typing.Optional[float] = OMIT,
        image_prompt_scale: typing.Optional[float] = OMIT,
        image_prompt_pos_x: typing.Optional[float] = OMIT,
        image_prompt_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[QrCodeRequestSelectedModel] = OMIT,
        selected_controlnet_model: typing.Optional[typing.List[QrCodeRequestSelectedControlnetModelItem]] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        controlnet_conditioning_scale: typing.Optional[typing.List[float]] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        scheduler: typing.Optional[QrCodeRequestScheduler] = OMIT,
        seed: typing.Optional[int] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> QrCodeGeneratorPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[QrCodeRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        qr_code_data : typing.Optional[str]

        qr_code_input_image : typing.Optional[core.File]
            See core.File for more documentation

        qr_code_vcard : typing.Optional[QrCodeRequestQrCodeVcard]

        qr_code_file : typing.Optional[core.File]
            See core.File for more documentation

        use_url_shortener : typing.Optional[bool]

        negative_prompt : typing.Optional[str]

        image_prompt : typing.Optional[str]

        image_prompt_controlnet_models : typing.Optional[typing.List[QrCodeRequestImagePromptControlnetModelsItem]]

        image_prompt_strength : typing.Optional[float]

        image_prompt_scale : typing.Optional[float]

        image_prompt_pos_x : typing.Optional[float]

        image_prompt_pos_y : typing.Optional[float]

        selected_model : typing.Optional[QrCodeRequestSelectedModel]

        selected_controlnet_model : typing.Optional[typing.List[QrCodeRequestSelectedControlnetModelItem]]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        controlnet_conditioning_scale : typing.Optional[typing.List[float]]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        scheduler : typing.Optional[QrCodeRequestScheduler]

        seed : typing.Optional[int]

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        QrCodeGeneratorPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.qr_code(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/art-qr-code/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "qr_code_data": qr_code_data,
                "qr_code_vcard": qr_code_vcard,
                "use_url_shortener": use_url_shortener,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "image_prompt": image_prompt,
                "image_prompt_controlnet_models": image_prompt_controlnet_models,
                "image_prompt_strength": image_prompt_strength,
                "image_prompt_scale": image_prompt_scale,
                "image_prompt_pos_x": image_prompt_pos_x,
                "image_prompt_pos_y": image_prompt_pos_y,
                "selected_model": selected_model,
                "selected_controlnet_model": selected_controlnet_model,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "controlnet_conditioning_scale": controlnet_conditioning_scale,
                "num_outputs": num_outputs,
                "quality": quality,
                "scheduler": scheduler,
                "seed": seed,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "settings": settings,
            },
            files={
                "qr_code_input_image": qr_code_input_image,
                "qr_code_file": qr_code_file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    QrCodeGeneratorPageOutput,
                    parse_obj_as(
                        type_=QrCodeGeneratorPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def seo_people_also_ask(
        self,
        *,
        search_query: str,
        site_filter: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[RelatedQnAPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RelatedQnAPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        embedding_model: typing.Optional[RelatedQnAPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[RelatedQnAPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RelatedQnAPageOutput:
        """
        Parameters
        ----------
        search_query : str

        site_filter : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[RelatedQnAPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[RelatedQnAPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[RelatedQnAPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[RelatedQnAPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RelatedQnAPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.seo_people_also_ask(
            search_query="search_query",
            site_filter="site_filter",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/related-qna-maker/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "site_filter": site_filter,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RelatedQnAPageOutput,
                    parse_obj_as(
                        type_=RelatedQnAPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def seo_content(
        self,
        *,
        search_query: str,
        keywords: str,
        title: str,
        company_url: str,
        example_id: typing.Optional[str] = None,
        task_instructions: typing.Optional[str] = OMIT,
        enable_html: typing.Optional[bool] = OMIT,
        selected_model: typing.Optional[SeoSummaryPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        enable_crosslinks: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SeoSummaryPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SeoSummaryPageOutput:
        """
        Parameters
        ----------
        search_query : str

        keywords : str

        title : str

        company_url : str

        example_id : typing.Optional[str]

        task_instructions : typing.Optional[str]

        enable_html : typing.Optional[bool]

        selected_model : typing.Optional[SeoSummaryPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        enable_crosslinks : typing.Optional[bool]

        seed : typing.Optional[int]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SeoSummaryPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SeoSummaryPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.seo_content(
            search_query="search_query",
            keywords="keywords",
            title="title",
            company_url="company_url",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/SEOSummary/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "search_query": search_query,
                "keywords": keywords,
                "title": title,
                "company_url": company_url,
                "task_instructions": task_instructions,
                "enable_html": enable_html,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "enable_crosslinks": enable_crosslinks,
                "seed": seed,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SeoSummaryPageOutput,
                    parse_obj_as(
                        type_=SeoSummaryPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def web_search_llm(
        self,
        *,
        search_query: str,
        site_filter: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[GoogleGptPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[GoogleGptPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        embedding_model: typing.Optional[GoogleGptPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[GoogleGptPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GoogleGptPageOutput:
        """
        Parameters
        ----------
        search_query : str

        site_filter : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[GoogleGptPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[GoogleGptPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[GoogleGptPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[GoogleGptPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GoogleGptPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.web_search_llm(
            search_query="search_query",
            site_filter="site_filter",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/google-gpt/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "site_filter": site_filter,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    GoogleGptPageOutput,
                    parse_obj_as(
                        type_=GoogleGptPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def personalize_email(
        self,
        *,
        email_address: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[SocialLookupEmailPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SocialLookupEmailPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SocialLookupEmailPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SocialLookupEmailPageOutput:
        """
        Parameters
        ----------
        email_address : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[SocialLookupEmailPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        selected_model : typing.Optional[SocialLookupEmailPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SocialLookupEmailPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SocialLookupEmailPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.personalize_email(
            email_address="email_address",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/SocialLookupEmail/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "email_address": email_address,
                "input_prompt": input_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SocialLookupEmailPageOutput,
                    parse_obj_as(
                        type_=SocialLookupEmailPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def bulk_run(
        self,
        *,
        documents: typing.List[core.File],
        run_urls: typing.List[str],
        input_columns: typing.Dict[str, str],
        output_columns: typing.Dict[str, str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[BulkRunRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        eval_urls: typing.Optional[typing.List[str]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BulkRunnerPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        run_urls : typing.List[str]

            Provide one or more Gooey.AI workflow runs.
            You can add multiple runs from the same recipe (e.g. two versions of your copilot) and we'll run the inputs over both of them.


        input_columns : typing.Dict[str, str]

            For each input field in the Gooey.AI workflow, specify the column in your input data that corresponds to it.


        output_columns : typing.Dict[str, str]

            For each output field in the Gooey.AI workflow, specify the column name that you'd like to use for it in the output data.


        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[BulkRunRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_urls : typing.Optional[typing.List[str]]

            _(optional)_ Add one or more Gooey.AI Evaluator Workflows to evaluate the results of your runs.


        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkRunnerPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.bulk_run(
            run_urls=["run_urls"],
            input_columns={"key": "value"},
            output_columns={"key": "value"},
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/bulk-runner/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "run_urls": run_urls,
                "input_columns": input_columns,
                "output_columns": output_columns,
                "eval_urls": eval_urls,
                "settings": settings,
            },
            files={
                "documents": documents,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BulkRunnerPageOutput,
                    parse_obj_as(
                        type_=BulkRunnerPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def eval(
        self,
        *,
        documents: typing.Sequence[str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[BulkEvalPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        eval_prompts: typing.Optional[typing.Sequence[BulkEvalPageRequestEvalPromptsItem]] = OMIT,
        agg_functions: typing.Optional[typing.Sequence[BulkEvalPageRequestAggFunctionsItem]] = OMIT,
        selected_model: typing.Optional[BulkEvalPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[BulkEvalPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BulkEvalPageOutput:
        """
        Parameters
        ----------
        documents : typing.Sequence[str]

            Upload or link to a CSV or google sheet that contains your sample input data.
            For example, for Copilot, this would sample questions or for Art QR Code, would would be pairs of image descriptions and URLs.
            Remember to includes header names in your CSV too.


        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[BulkEvalPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_prompts : typing.Optional[typing.Sequence[BulkEvalPageRequestEvalPromptsItem]]

            Specify custom LLM prompts to calculate metrics that evaluate each row of the input data. The output should be a JSON object mapping the metric names to values.
            _The `columns` dictionary can be used to reference the spreadsheet columns._


        agg_functions : typing.Optional[typing.Sequence[BulkEvalPageRequestAggFunctionsItem]]

            Aggregate using one or more operations. Uses [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#dataframegroupby-computations-descriptive-stats).


        selected_model : typing.Optional[BulkEvalPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[BulkEvalPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkEvalPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.eval(
            documents=["documents"],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/bulk-eval/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "documents": documents,
                "eval_prompts": eval_prompts,
                "agg_functions": agg_functions,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BulkEvalPageOutput,
                    parse_obj_as(
                        type_=BulkEvalPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def synthesize_data(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[SynthesizeDataRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        sheet_url: typing.Optional[core.File] = OMIT,
        selected_asr_model: typing.Optional[SynthesizeDataRequestSelectedAsrModel] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SynthesizeDataRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SynthesizeDataRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocExtractPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[SynthesizeDataRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        sheet_url : typing.Optional[core.File]
            See core.File for more documentation

        selected_asr_model : typing.Optional[SynthesizeDataRequestSelectedAsrModel]

        google_translate_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        task_instructions : typing.Optional[str]

        selected_model : typing.Optional[SynthesizeDataRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SynthesizeDataRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocExtractPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.synthesize_data()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/doc-extract/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_asr_model": selected_asr_model,
                "google_translate_target": google_translate_target,
                "task_instructions": task_instructions,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            files={
                "documents": documents,
                "sheet_url": sheet_url,
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocExtractPageOutput,
                    parse_obj_as(
                        type_=DocExtractPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def llm(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[CompareLlmPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_prompt: typing.Optional[str] = OMIT,
        selected_models: typing.Optional[typing.Sequence[CompareLlmPageRequestSelectedModelsItem]] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[CompareLlmPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareLlmPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[CompareLlmPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        selected_models : typing.Optional[typing.Sequence[CompareLlmPageRequestSelectedModelsItem]]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[CompareLlmPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareLlmPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.llm()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/CompareLLM/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "selected_models": selected_models,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareLlmPageOutput,
                    parse_obj_as(
                        type_=CompareLlmPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def rag(
        self,
        *,
        search_query: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[DocSearchPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        keyword_query: typing.Optional[DocSearchPageRequestKeywordQuery] = OMIT,
        documents: typing.Optional[typing.Sequence[str]] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        doc_extract_url: typing.Optional[str] = OMIT,
        embedding_model: typing.Optional[DocSearchPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[DocSearchPageRequestSelectedModel] = OMIT,
        citation_style: typing.Optional[DocSearchPageRequestCitationStyle] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[DocSearchPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocSearchPageOutput:
        """
        Parameters
        ----------
        search_query : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[DocSearchPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        keyword_query : typing.Optional[DocSearchPageRequestKeywordQuery]

        documents : typing.Optional[typing.Sequence[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        doc_extract_url : typing.Optional[str]

        embedding_model : typing.Optional[DocSearchPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[DocSearchPageRequestSelectedModel]

        citation_style : typing.Optional[DocSearchPageRequestCitationStyle]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[DocSearchPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocSearchPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.rag(
            search_query="search_query",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/doc-search/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "keyword_query": keyword_query,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "doc_extract_url": doc_extract_url,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "citation_style": citation_style,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocSearchPageOutput,
                    parse_obj_as(
                        type_=DocSearchPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def smart_gpt(
        self,
        *,
        input_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[SmartGptPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        cot_prompt: typing.Optional[str] = OMIT,
        reflexion_prompt: typing.Optional[str] = OMIT,
        dera_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SmartGptPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SmartGptPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SmartGptPageOutput:
        """
        Parameters
        ----------
        input_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[SmartGptPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        cot_prompt : typing.Optional[str]

        reflexion_prompt : typing.Optional[str]

        dera_prompt : typing.Optional[str]

        selected_model : typing.Optional[SmartGptPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SmartGptPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SmartGptPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.smart_gpt(
            input_prompt="input_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/SmartGPT/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "cot_prompt": cot_prompt,
                "reflexion_prompt": reflexion_prompt,
                "dera_prompt": dera_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SmartGptPageOutput,
                    parse_obj_as(
                        type_=SmartGptPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def doc_summary(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[DocSummaryRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        merge_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[DocSummaryRequestSelectedModel] = OMIT,
        chain_type: typing.Optional[typing.Literal["map_reduce"]] = OMIT,
        selected_asr_model: typing.Optional[DocSummaryRequestSelectedAsrModel] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[DocSummaryRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocSummaryPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[DocSummaryRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        merge_instructions : typing.Optional[str]

        selected_model : typing.Optional[DocSummaryRequestSelectedModel]

        chain_type : typing.Optional[typing.Literal["map_reduce"]]

        selected_asr_model : typing.Optional[DocSummaryRequestSelectedAsrModel]

        google_translate_target : typing.Optional[str]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[DocSummaryRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocSummaryPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.doc_summary()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/doc-summary/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "task_instructions": task_instructions,
                "merge_instructions": merge_instructions,
                "selected_model": selected_model,
                "chain_type": chain_type,
                "selected_asr_model": selected_asr_model,
                "google_translate_target": google_translate_target,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            files={
                "documents": documents,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocSummaryPageOutput,
                    parse_obj_as(
                        type_=DocSummaryPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def functions(
        self,
        *,
        example_id: typing.Optional[str] = None,
        code: typing.Optional[str] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FunctionsPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        code : typing.Optional[str]
            The JS code to be executed.

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used in the code

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FunctionsPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.functions()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/functions/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "code": code,
                "variables": variables,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    FunctionsPageOutput,
                    parse_obj_as(
                        type_=FunctionsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def lipsync(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[LipsyncRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_face: typing.Optional[core.File] = OMIT,
        face_padding_top: typing.Optional[int] = OMIT,
        face_padding_bottom: typing.Optional[int] = OMIT,
        face_padding_left: typing.Optional[int] = OMIT,
        face_padding_right: typing.Optional[int] = OMIT,
        sadtalker_settings: typing.Optional[LipsyncRequestSadtalkerSettings] = OMIT,
        selected_model: typing.Optional[LipsyncRequestSelectedModel] = OMIT,
        input_audio: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LipsyncPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[LipsyncRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_face : typing.Optional[core.File]
            See core.File for more documentation

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[LipsyncRequestSadtalkerSettings]

        selected_model : typing.Optional[LipsyncRequestSelectedModel]

        input_audio : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LipsyncPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.lipsync()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/Lipsync/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "selected_model": selected_model,
                "settings": settings,
            },
            files={
                "input_face": input_face,
                "input_audio": input_audio,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    LipsyncPageOutput,
                    parse_obj_as(
                        type_=LipsyncPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def lipsync_tts(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[LipsyncTtsRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        tts_provider: typing.Optional[LipsyncTtsRequestTtsProvider] = OMIT,
        uberduck_voice_name: typing.Optional[str] = OMIT,
        uberduck_speaking_rate: typing.Optional[float] = OMIT,
        google_voice_name: typing.Optional[str] = OMIT,
        google_speaking_rate: typing.Optional[float] = OMIT,
        google_pitch: typing.Optional[float] = OMIT,
        bark_history_prompt: typing.Optional[str] = OMIT,
        elevenlabs_voice_name: typing.Optional[str] = OMIT,
        elevenlabs_api_key: typing.Optional[str] = OMIT,
        elevenlabs_voice_id: typing.Optional[str] = OMIT,
        elevenlabs_model: typing.Optional[str] = OMIT,
        elevenlabs_stability: typing.Optional[float] = OMIT,
        elevenlabs_similarity_boost: typing.Optional[float] = OMIT,
        elevenlabs_style: typing.Optional[float] = OMIT,
        elevenlabs_speaker_boost: typing.Optional[bool] = OMIT,
        azure_voice_name: typing.Optional[str] = OMIT,
        openai_voice_name: typing.Optional[LipsyncTtsRequestOpenaiVoiceName] = OMIT,
        openai_tts_model: typing.Optional[LipsyncTtsRequestOpenaiTtsModel] = OMIT,
        input_face: typing.Optional[core.File] = OMIT,
        face_padding_top: typing.Optional[int] = OMIT,
        face_padding_bottom: typing.Optional[int] = OMIT,
        face_padding_left: typing.Optional[int] = OMIT,
        face_padding_right: typing.Optional[int] = OMIT,
        sadtalker_settings: typing.Optional[LipsyncTtsRequestSadtalkerSettings] = OMIT,
        selected_model: typing.Optional[LipsyncTtsRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LipsyncTtsPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[LipsyncTtsRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        tts_provider : typing.Optional[LipsyncTtsRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[LipsyncTtsRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[LipsyncTtsRequestOpenaiTtsModel]

        input_face : typing.Optional[core.File]
            See core.File for more documentation

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[LipsyncTtsRequestSadtalkerSettings]

        selected_model : typing.Optional[LipsyncTtsRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LipsyncTtsPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.lipsync_tts(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/LipsyncTTS/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "selected_model": selected_model,
                "settings": settings,
            },
            files={
                "input_face": input_face,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    LipsyncTtsPageOutput,
                    parse_obj_as(
                        type_=LipsyncTtsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def text_to_speech(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[TextToSpeechPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        tts_provider: typing.Optional[TextToSpeechPageRequestTtsProvider] = OMIT,
        uberduck_voice_name: typing.Optional[str] = OMIT,
        uberduck_speaking_rate: typing.Optional[float] = OMIT,
        google_voice_name: typing.Optional[str] = OMIT,
        google_speaking_rate: typing.Optional[float] = OMIT,
        google_pitch: typing.Optional[float] = OMIT,
        bark_history_prompt: typing.Optional[str] = OMIT,
        elevenlabs_voice_name: typing.Optional[str] = OMIT,
        elevenlabs_api_key: typing.Optional[str] = OMIT,
        elevenlabs_voice_id: typing.Optional[str] = OMIT,
        elevenlabs_model: typing.Optional[str] = OMIT,
        elevenlabs_stability: typing.Optional[float] = OMIT,
        elevenlabs_similarity_boost: typing.Optional[float] = OMIT,
        elevenlabs_style: typing.Optional[float] = OMIT,
        elevenlabs_speaker_boost: typing.Optional[bool] = OMIT,
        azure_voice_name: typing.Optional[str] = OMIT,
        openai_voice_name: typing.Optional[TextToSpeechPageRequestOpenaiVoiceName] = OMIT,
        openai_tts_model: typing.Optional[TextToSpeechPageRequestOpenaiTtsModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TextToSpeechPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[TextToSpeechPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        tts_provider : typing.Optional[TextToSpeechPageRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[TextToSpeechPageRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[TextToSpeechPageRequestOpenaiTtsModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TextToSpeechPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.text_to_speech(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/TextToSpeech/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    TextToSpeechPageOutput,
                    parse_obj_as(
                        type_=TextToSpeechPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def speech_recognition(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[SpeechRecognitionRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[SpeechRecognitionRequestSelectedModel] = OMIT,
        language: typing.Optional[str] = OMIT,
        translation_model: typing.Optional[SpeechRecognitionRequestTranslationModel] = OMIT,
        output_format: typing.Optional[SpeechRecognitionRequestOutputFormat] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        translation_source: typing.Optional[str] = OMIT,
        translation_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsrPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[SpeechRecognitionRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[SpeechRecognitionRequestSelectedModel]

        language : typing.Optional[str]

        translation_model : typing.Optional[SpeechRecognitionRequestTranslationModel]

        output_format : typing.Optional[SpeechRecognitionRequestOutputFormat]

        google_translate_target : typing.Optional[str]
            use `translation_model` & `translation_target` instead.

        translation_source : typing.Optional[str]

        translation_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsrPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.speech_recognition()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/asr/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_model": selected_model,
                "language": language,
                "translation_model": translation_model,
                "output_format": output_format,
                "google_translate_target": google_translate_target,
                "translation_source": translation_source,
                "translation_target": translation_target,
                "settings": settings,
            },
            files={
                "documents": documents,
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    AsrPageOutput,
                    parse_obj_as(
                        type_=AsrPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def text_to_music(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[Text2AudioPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        duration_sec: typing.Optional[float] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        selected_models: typing.Optional[typing.Sequence[typing.Literal["audio_ldm"]]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Text2AudioPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[Text2AudioPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        negative_prompt : typing.Optional[str]

        duration_sec : typing.Optional[float]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        sd2upscaling : typing.Optional[bool]

        selected_models : typing.Optional[typing.Sequence[typing.Literal["audio_ldm"]]]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Text2AudioPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.text_to_music(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/text2audio/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "duration_sec": duration_sec,
                "num_outputs": num_outputs,
                "quality": quality,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "sd_2_upscaling": sd2upscaling,
                "selected_models": selected_models,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Text2AudioPageOutput,
                    parse_obj_as(
                        type_=Text2AudioPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def translate(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[TranslateRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        texts: typing.Optional[typing.List[str]] = OMIT,
        selected_model: typing.Optional[TranslateRequestSelectedModel] = OMIT,
        translation_source: typing.Optional[str] = OMIT,
        translation_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranslationPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[TranslateRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        texts : typing.Optional[typing.List[str]]

        selected_model : typing.Optional[TranslateRequestSelectedModel]

        translation_source : typing.Optional[str]

        translation_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranslationPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.translate()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/translate/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "translation_source": translation_source,
                "translation_target": translation_target,
                "settings": settings,
            },
            files={
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    TranslationPageOutput,
                    parse_obj_as(
                        type_=TranslationPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def remix_image(
        self,
        *,
        input_image: core.File,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[RemixImageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        text_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RemixImageRequestSelectedModel] = OMIT,
        selected_controlnet_model: typing.Optional[RemixImageRequestSelectedControlnetModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        prompt_strength: typing.Optional[float] = OMIT,
        controlnet_conditioning_scale: typing.Optional[typing.List[float]] = OMIT,
        seed: typing.Optional[int] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Img2ImgPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[RemixImageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        text_prompt : typing.Optional[str]

        selected_model : typing.Optional[RemixImageRequestSelectedModel]

        selected_controlnet_model : typing.Optional[RemixImageRequestSelectedControlnetModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        prompt_strength : typing.Optional[float]

        controlnet_conditioning_scale : typing.Optional[typing.List[float]]

        seed : typing.Optional[int]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Img2ImgPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.remix_image()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/Img2Img/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "selected_model": selected_model,
                "selected_controlnet_model": selected_controlnet_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "prompt_strength": prompt_strength,
                "controlnet_conditioning_scale": controlnet_conditioning_scale,
                "seed": seed,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Img2ImgPageOutput,
                    parse_obj_as(
                        type_=Img2ImgPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def text_to_image(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[CompareText2ImgPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        dall_e3quality: typing.Optional[str] = OMIT,
        dall_e3style: typing.Optional[str] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        selected_models: typing.Optional[typing.Sequence[CompareText2ImgPageRequestSelectedModelsItem]] = OMIT,
        scheduler: typing.Optional[CompareText2ImgPageRequestScheduler] = OMIT,
        edit_instruction: typing.Optional[str] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareText2ImgPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[CompareText2ImgPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        negative_prompt : typing.Optional[str]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        dall_e3quality : typing.Optional[str]

        dall_e3style : typing.Optional[str]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        sd2upscaling : typing.Optional[bool]

        selected_models : typing.Optional[typing.Sequence[CompareText2ImgPageRequestSelectedModelsItem]]

        scheduler : typing.Optional[CompareText2ImgPageRequestScheduler]

        edit_instruction : typing.Optional[str]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareText2ImgPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.text_to_image(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/CompareText2Img/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "output_width": output_width,
                "output_height": output_height,
                "num_outputs": num_outputs,
                "quality": quality,
                "dall_e_3_quality": dall_e3quality,
                "dall_e_3_style": dall_e3style,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "sd_2_upscaling": sd2upscaling,
                "selected_models": selected_models,
                "scheduler": scheduler,
                "edit_instruction": edit_instruction,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareText2ImgPageOutput,
                    parse_obj_as(
                        type_=CompareText2ImgPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def product_image(
        self,
        *,
        input_image: core.File,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[ProductImageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        mask_threshold: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[ProductImageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ObjectInpaintingPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[ProductImageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        mask_threshold : typing.Optional[float]

        selected_model : typing.Optional[ProductImageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        sd2upscaling : typing.Optional[bool]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ObjectInpaintingPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.product_image(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/ObjectInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "mask_threshold": mask_threshold,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "sd_2_upscaling": sd2upscaling,
                "seed": seed,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ObjectInpaintingPageOutput,
                    parse_obj_as(
                        type_=ObjectInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def portrait(
        self,
        *,
        input_image: core.File,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[PortraitRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        face_scale: typing.Optional[float] = OMIT,
        face_pos_x: typing.Optional[float] = OMIT,
        face_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[PortraitRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        upscale_factor: typing.Optional[float] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FaceInpaintingPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[PortraitRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        face_scale : typing.Optional[float]

        face_pos_x : typing.Optional[float]

        face_pos_y : typing.Optional[float]

        selected_model : typing.Optional[PortraitRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        upscale_factor : typing.Optional[float]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FaceInpaintingPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.portrait(
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/FaceInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "face_scale": face_scale,
                "face_pos_x": face_pos_x,
                "face_pos_y": face_pos_y,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "upscale_factor": upscale_factor,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    FaceInpaintingPageOutput,
                    parse_obj_as(
                        type_=FaceInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def image_from_email(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[EmailFaceInpaintingPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        email_address: typing.Optional[str] = OMIT,
        twitter_handle: typing.Optional[str] = OMIT,
        face_scale: typing.Optional[float] = OMIT,
        face_pos_x: typing.Optional[float] = OMIT,
        face_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[EmailFaceInpaintingPageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        upscale_factor: typing.Optional[float] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        should_send_email: typing.Optional[bool] = OMIT,
        email_from: typing.Optional[str] = OMIT,
        email_cc: typing.Optional[str] = OMIT,
        email_bcc: typing.Optional[str] = OMIT,
        email_subject: typing.Optional[str] = OMIT,
        email_body: typing.Optional[str] = OMIT,
        email_body_enable_html: typing.Optional[bool] = OMIT,
        fallback_email_body: typing.Optional[str] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmailFaceInpaintingPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[EmailFaceInpaintingPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        email_address : typing.Optional[str]

        twitter_handle : typing.Optional[str]

        face_scale : typing.Optional[float]

        face_pos_x : typing.Optional[float]

        face_pos_y : typing.Optional[float]

        selected_model : typing.Optional[EmailFaceInpaintingPageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        upscale_factor : typing.Optional[float]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        should_send_email : typing.Optional[bool]

        email_from : typing.Optional[str]

        email_cc : typing.Optional[str]

        email_bcc : typing.Optional[str]

        email_subject : typing.Optional[str]

        email_body : typing.Optional[str]

        email_body_enable_html : typing.Optional[bool]

        fallback_email_body : typing.Optional[str]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmailFaceInpaintingPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.image_from_email(
            email_address="sean@dara.network",
            text_prompt="winter's day in paris",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/EmailFaceInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "email_address": email_address,
                "twitter_handle": twitter_handle,
                "text_prompt": text_prompt,
                "face_scale": face_scale,
                "face_pos_x": face_pos_x,
                "face_pos_y": face_pos_y,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "upscale_factor": upscale_factor,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "should_send_email": should_send_email,
                "email_from": email_from,
                "email_cc": email_cc,
                "email_bcc": email_bcc,
                "email_subject": email_subject,
                "email_body": email_body,
                "email_body_enable_html": email_body_enable_html,
                "fallback_email_body": fallback_email_body,
                "seed": seed,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmailFaceInpaintingPageOutput,
                    parse_obj_as(
                        type_=EmailFaceInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def image_from_web_search(
        self,
        *,
        search_query: str,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[GoogleImageGenPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        selected_model: typing.Optional[GoogleImageGenPageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        prompt_strength: typing.Optional[float] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GoogleImageGenPageOutput:
        """
        Parameters
        ----------
        search_query : str

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[GoogleImageGenPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        selected_model : typing.Optional[GoogleImageGenPageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        prompt_strength : typing.Optional[float]

        sd2upscaling : typing.Optional[bool]

        seed : typing.Optional[int]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GoogleImageGenPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.image_from_web_search(
            search_query="search_query",
            text_prompt="text_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/GoogleImageGen/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "search_query": search_query,
                "text_prompt": text_prompt,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "guidance_scale": guidance_scale,
                "prompt_strength": prompt_strength,
                "sd_2_upscaling": sd2upscaling,
                "seed": seed,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    GoogleImageGenPageOutput,
                    parse_obj_as(
                        type_=GoogleImageGenPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def remove_background(
        self,
        *,
        input_image: core.File,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[RemoveBackgroundRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[RemoveBackgroundRequestSelectedModel] = OMIT,
        mask_threshold: typing.Optional[float] = OMIT,
        rect_persepective_transform: typing.Optional[bool] = OMIT,
        reflection_opacity: typing.Optional[float] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ImageSegmentationPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[RemoveBackgroundRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[RemoveBackgroundRequestSelectedModel]

        mask_threshold : typing.Optional[float]

        rect_persepective_transform : typing.Optional[bool]

        reflection_opacity : typing.Optional[float]

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ImageSegmentationPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.remove_background()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/ImageSegmentation/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_model": selected_model,
                "mask_threshold": mask_threshold,
                "rect_persepective_transform": rect_persepective_transform,
                "reflection_opacity": reflection_opacity,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ImageSegmentationPageOutput,
                    parse_obj_as(
                        type_=ImageSegmentationPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upscale(
        self,
        *,
        scale: int,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[UpscaleRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_image: typing.Optional[core.File] = OMIT,
        input_video: typing.Optional[core.File] = OMIT,
        selected_models: typing.Optional[typing.List[UpscaleRequestSelectedModelsItem]] = OMIT,
        selected_bg_model: typing.Optional[typing.Literal["real_esrgan_x2"]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareUpscalerPageOutput:
        """
        Parameters
        ----------
        scale : int
            The final upsampling scale of the image

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[UpscaleRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_image : typing.Optional[core.File]
            See core.File for more documentation

        input_video : typing.Optional[core.File]
            See core.File for more documentation

        selected_models : typing.Optional[typing.List[UpscaleRequestSelectedModelsItem]]

        selected_bg_model : typing.Optional[typing.Literal["real_esrgan_x2"]]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareUpscalerPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.upscale(
            scale=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/compare-ai-upscalers/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "scale": scale,
                "selected_models": selected_models,
                "selected_bg_model": selected_bg_model,
                "settings": settings,
            },
            files={
                "input_image": input_image,
                "input_video": input_video,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareUpscalerPageOutput,
                    parse_obj_as(
                        type_=CompareUpscalerPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def embed(
        self,
        *,
        texts: typing.Sequence[str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[EmbeddingsPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[EmbeddingsPageRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmbeddingsPageOutput:
        """
        Parameters
        ----------
        texts : typing.Sequence[str]

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[EmbeddingsPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[EmbeddingsPageRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingsPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.embed(
            texts=["texts"],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/embeddings/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmbeddingsPageOutput,
                    parse_obj_as(
                        type_=EmbeddingsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def seo_people_also_ask_doc(
        self,
        *,
        search_query: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[RelatedQnADocPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        keyword_query: typing.Optional[RelatedQnADocPageRequestKeywordQuery] = OMIT,
        documents: typing.Optional[typing.Sequence[str]] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        doc_extract_url: typing.Optional[str] = OMIT,
        embedding_model: typing.Optional[RelatedQnADocPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RelatedQnADocPageRequestSelectedModel] = OMIT,
        citation_style: typing.Optional[RelatedQnADocPageRequestCitationStyle] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[RelatedQnADocPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RelatedQnADocPageOutput:
        """
        Parameters
        ----------
        search_query : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[RelatedQnADocPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        keyword_query : typing.Optional[RelatedQnADocPageRequestKeywordQuery]

        documents : typing.Optional[typing.Sequence[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        doc_extract_url : typing.Optional[str]

        embedding_model : typing.Optional[RelatedQnADocPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[RelatedQnADocPageRequestSelectedModel]

        citation_style : typing.Optional[RelatedQnADocPageRequestCitationStyle]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[RelatedQnADocPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RelatedQnADocPageOutput
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.seo_people_also_ask_doc(
            search_query="search_query",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/related-qna-maker-doc/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "keyword_query": keyword_query,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "doc_extract_url": doc_extract_url,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "citation_style": citation_style,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RelatedQnADocPageOutput,
                    parse_obj_as(
                        type_=RelatedQnADocPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_balance(self, *, request_options: typing.Optional[RequestOptions] = None) -> BalanceResponse:
        """
        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BalanceResponse
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.get_balance()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v1/balance/",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BalanceResponse,
                    parse_obj_as(
                        type_=BalanceResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncGooey:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : typing.Optional[str]
        The base url to use for requests from the client.

    environment : GooeyEnvironment
        The environment to use for requests from the client. from .environment import GooeyEnvironment



        Defaults to GooeyEnvironment.DEFAULT



    api_key : typing.Optional[typing.Union[str, typing.Callable[[], str]]]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.AsyncClient]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from gooey import AsyncGooey

    client = AsyncGooey(
        api_key="YOUR_API_KEY",
    )
    """

    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: GooeyEnvironment = GooeyEnvironment.DEFAULT,
        api_key: typing.Optional[typing.Union[str, typing.Callable[[], str]]] = os.getenv("GOOEY_API_KEY"),
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.AsyncClient] = None,
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        if api_key is None:
            raise ApiError(body="The client must be instantiated be either passing in api_key or setting GOOEY_API_KEY")
        self._client_wrapper = AsyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            api_key=api_key,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.copilot = AsyncCopilotClient(client_wrapper=self._client_wrapper)

    async def animate(
        self,
        *,
        animation_prompts: typing.Sequence[DeforumSdPageRequestAnimationPromptsItem],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[DeforumSdPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        max_frames: typing.Optional[int] = OMIT,
        selected_model: typing.Optional[DeforumSdPageRequestSelectedModel] = OMIT,
        animation_mode: typing.Optional[str] = OMIT,
        zoom: typing.Optional[str] = OMIT,
        translation_x: typing.Optional[str] = OMIT,
        translation_y: typing.Optional[str] = OMIT,
        rotation3d_x: typing.Optional[str] = OMIT,
        rotation3d_y: typing.Optional[str] = OMIT,
        rotation3d_z: typing.Optional[str] = OMIT,
        fps: typing.Optional[int] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeforumSdPageOutput:
        """
        Parameters
        ----------
        animation_prompts : typing.Sequence[DeforumSdPageRequestAnimationPromptsItem]

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[DeforumSdPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        max_frames : typing.Optional[int]

        selected_model : typing.Optional[DeforumSdPageRequestSelectedModel]

        animation_mode : typing.Optional[str]

        zoom : typing.Optional[str]

        translation_x : typing.Optional[str]

        translation_y : typing.Optional[str]

        rotation3d_x : typing.Optional[str]

        rotation3d_y : typing.Optional[str]

        rotation3d_z : typing.Optional[str]

        fps : typing.Optional[int]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeforumSdPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey, DeforumSdPageRequestAnimationPromptsItem

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.animate(
                animation_prompts=[
                    DeforumSdPageRequestAnimationPromptsItem(
                        frame="frame",
                        prompt="prompt",
                    )
                ],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/DeforumSD/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "animation_prompts": animation_prompts,
                "max_frames": max_frames,
                "selected_model": selected_model,
                "animation_mode": animation_mode,
                "zoom": zoom,
                "translation_x": translation_x,
                "translation_y": translation_y,
                "rotation_3d_x": rotation3d_x,
                "rotation_3d_y": rotation3d_y,
                "rotation_3d_z": rotation3d_z,
                "fps": fps,
                "seed": seed,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DeforumSdPageOutput,
                    parse_obj_as(
                        type_=DeforumSdPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def qr_code(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[QrCodeRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        qr_code_data: typing.Optional[str] = OMIT,
        qr_code_input_image: typing.Optional[core.File] = OMIT,
        qr_code_vcard: typing.Optional[QrCodeRequestQrCodeVcard] = OMIT,
        qr_code_file: typing.Optional[core.File] = OMIT,
        use_url_shortener: typing.Optional[bool] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        image_prompt: typing.Optional[str] = OMIT,
        image_prompt_controlnet_models: typing.Optional[
            typing.List[QrCodeRequestImagePromptControlnetModelsItem]
        ] = OMIT,
        image_prompt_strength: typing.Optional[float] = OMIT,
        image_prompt_scale: typing.Optional[float] = OMIT,
        image_prompt_pos_x: typing.Optional[float] = OMIT,
        image_prompt_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[QrCodeRequestSelectedModel] = OMIT,
        selected_controlnet_model: typing.Optional[typing.List[QrCodeRequestSelectedControlnetModelItem]] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        controlnet_conditioning_scale: typing.Optional[typing.List[float]] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        scheduler: typing.Optional[QrCodeRequestScheduler] = OMIT,
        seed: typing.Optional[int] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> QrCodeGeneratorPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[QrCodeRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        qr_code_data : typing.Optional[str]

        qr_code_input_image : typing.Optional[core.File]
            See core.File for more documentation

        qr_code_vcard : typing.Optional[QrCodeRequestQrCodeVcard]

        qr_code_file : typing.Optional[core.File]
            See core.File for more documentation

        use_url_shortener : typing.Optional[bool]

        negative_prompt : typing.Optional[str]

        image_prompt : typing.Optional[str]

        image_prompt_controlnet_models : typing.Optional[typing.List[QrCodeRequestImagePromptControlnetModelsItem]]

        image_prompt_strength : typing.Optional[float]

        image_prompt_scale : typing.Optional[float]

        image_prompt_pos_x : typing.Optional[float]

        image_prompt_pos_y : typing.Optional[float]

        selected_model : typing.Optional[QrCodeRequestSelectedModel]

        selected_controlnet_model : typing.Optional[typing.List[QrCodeRequestSelectedControlnetModelItem]]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        controlnet_conditioning_scale : typing.Optional[typing.List[float]]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        scheduler : typing.Optional[QrCodeRequestScheduler]

        seed : typing.Optional[int]

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        QrCodeGeneratorPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.qr_code(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/art-qr-code/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "qr_code_data": qr_code_data,
                "qr_code_vcard": qr_code_vcard,
                "use_url_shortener": use_url_shortener,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "image_prompt": image_prompt,
                "image_prompt_controlnet_models": image_prompt_controlnet_models,
                "image_prompt_strength": image_prompt_strength,
                "image_prompt_scale": image_prompt_scale,
                "image_prompt_pos_x": image_prompt_pos_x,
                "image_prompt_pos_y": image_prompt_pos_y,
                "selected_model": selected_model,
                "selected_controlnet_model": selected_controlnet_model,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "controlnet_conditioning_scale": controlnet_conditioning_scale,
                "num_outputs": num_outputs,
                "quality": quality,
                "scheduler": scheduler,
                "seed": seed,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "settings": settings,
            },
            files={
                "qr_code_input_image": qr_code_input_image,
                "qr_code_file": qr_code_file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    QrCodeGeneratorPageOutput,
                    parse_obj_as(
                        type_=QrCodeGeneratorPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def seo_people_also_ask(
        self,
        *,
        search_query: str,
        site_filter: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[RelatedQnAPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RelatedQnAPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        embedding_model: typing.Optional[RelatedQnAPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[RelatedQnAPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RelatedQnAPageOutput:
        """
        Parameters
        ----------
        search_query : str

        site_filter : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[RelatedQnAPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[RelatedQnAPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[RelatedQnAPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[RelatedQnAPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RelatedQnAPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.seo_people_also_ask(
                search_query="search_query",
                site_filter="site_filter",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/related-qna-maker/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "site_filter": site_filter,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RelatedQnAPageOutput,
                    parse_obj_as(
                        type_=RelatedQnAPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def seo_content(
        self,
        *,
        search_query: str,
        keywords: str,
        title: str,
        company_url: str,
        example_id: typing.Optional[str] = None,
        task_instructions: typing.Optional[str] = OMIT,
        enable_html: typing.Optional[bool] = OMIT,
        selected_model: typing.Optional[SeoSummaryPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        enable_crosslinks: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SeoSummaryPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SeoSummaryPageOutput:
        """
        Parameters
        ----------
        search_query : str

        keywords : str

        title : str

        company_url : str

        example_id : typing.Optional[str]

        task_instructions : typing.Optional[str]

        enable_html : typing.Optional[bool]

        selected_model : typing.Optional[SeoSummaryPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        enable_crosslinks : typing.Optional[bool]

        seed : typing.Optional[int]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SeoSummaryPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SeoSummaryPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.seo_content(
                search_query="search_query",
                keywords="keywords",
                title="title",
                company_url="company_url",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/SEOSummary/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "search_query": search_query,
                "keywords": keywords,
                "title": title,
                "company_url": company_url,
                "task_instructions": task_instructions,
                "enable_html": enable_html,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "enable_crosslinks": enable_crosslinks,
                "seed": seed,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SeoSummaryPageOutput,
                    parse_obj_as(
                        type_=SeoSummaryPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def web_search_llm(
        self,
        *,
        search_query: str,
        site_filter: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[GoogleGptPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[GoogleGptPageRequestSelectedModel] = OMIT,
        max_search_urls: typing.Optional[int] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        embedding_model: typing.Optional[GoogleGptPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[GoogleGptPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GoogleGptPageOutput:
        """
        Parameters
        ----------
        search_query : str

        site_filter : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[GoogleGptPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[GoogleGptPageRequestSelectedModel]

        max_search_urls : typing.Optional[int]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[GoogleGptPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[GoogleGptPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GoogleGptPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.web_search_llm(
                search_query="search_query",
                site_filter="site_filter",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/google-gpt/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "site_filter": site_filter,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "max_search_urls": max_search_urls,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    GoogleGptPageOutput,
                    parse_obj_as(
                        type_=GoogleGptPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def personalize_email(
        self,
        *,
        email_address: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[SocialLookupEmailPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SocialLookupEmailPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SocialLookupEmailPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SocialLookupEmailPageOutput:
        """
        Parameters
        ----------
        email_address : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[SocialLookupEmailPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        selected_model : typing.Optional[SocialLookupEmailPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SocialLookupEmailPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SocialLookupEmailPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.personalize_email(
                email_address="email_address",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/SocialLookupEmail/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "email_address": email_address,
                "input_prompt": input_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SocialLookupEmailPageOutput,
                    parse_obj_as(
                        type_=SocialLookupEmailPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def bulk_run(
        self,
        *,
        documents: typing.List[core.File],
        run_urls: typing.List[str],
        input_columns: typing.Dict[str, str],
        output_columns: typing.Dict[str, str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[BulkRunRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        eval_urls: typing.Optional[typing.List[str]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BulkRunnerPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        run_urls : typing.List[str]

            Provide one or more Gooey.AI workflow runs.
            You can add multiple runs from the same recipe (e.g. two versions of your copilot) and we'll run the inputs over both of them.


        input_columns : typing.Dict[str, str]

            For each input field in the Gooey.AI workflow, specify the column in your input data that corresponds to it.


        output_columns : typing.Dict[str, str]

            For each output field in the Gooey.AI workflow, specify the column name that you'd like to use for it in the output data.


        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[BulkRunRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_urls : typing.Optional[typing.List[str]]

            _(optional)_ Add one or more Gooey.AI Evaluator Workflows to evaluate the results of your runs.


        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkRunnerPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.bulk_run(
                run_urls=["run_urls"],
                input_columns={"key": "value"},
                output_columns={"key": "value"},
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/bulk-runner/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "run_urls": run_urls,
                "input_columns": input_columns,
                "output_columns": output_columns,
                "eval_urls": eval_urls,
                "settings": settings,
            },
            files={
                "documents": documents,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BulkRunnerPageOutput,
                    parse_obj_as(
                        type_=BulkRunnerPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def eval(
        self,
        *,
        documents: typing.Sequence[str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[BulkEvalPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        eval_prompts: typing.Optional[typing.Sequence[BulkEvalPageRequestEvalPromptsItem]] = OMIT,
        agg_functions: typing.Optional[typing.Sequence[BulkEvalPageRequestAggFunctionsItem]] = OMIT,
        selected_model: typing.Optional[BulkEvalPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[BulkEvalPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BulkEvalPageOutput:
        """
        Parameters
        ----------
        documents : typing.Sequence[str]

            Upload or link to a CSV or google sheet that contains your sample input data.
            For example, for Copilot, this would sample questions or for Art QR Code, would would be pairs of image descriptions and URLs.
            Remember to includes header names in your CSV too.


        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[BulkEvalPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_prompts : typing.Optional[typing.Sequence[BulkEvalPageRequestEvalPromptsItem]]

            Specify custom LLM prompts to calculate metrics that evaluate each row of the input data. The output should be a JSON object mapping the metric names to values.
            _The `columns` dictionary can be used to reference the spreadsheet columns._


        agg_functions : typing.Optional[typing.Sequence[BulkEvalPageRequestAggFunctionsItem]]

            Aggregate using one or more operations. Uses [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#dataframegroupby-computations-descriptive-stats).


        selected_model : typing.Optional[BulkEvalPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[BulkEvalPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkEvalPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.eval(
                documents=["documents"],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/bulk-eval/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "documents": documents,
                "eval_prompts": eval_prompts,
                "agg_functions": agg_functions,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BulkEvalPageOutput,
                    parse_obj_as(
                        type_=BulkEvalPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def synthesize_data(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[SynthesizeDataRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        sheet_url: typing.Optional[core.File] = OMIT,
        selected_asr_model: typing.Optional[SynthesizeDataRequestSelectedAsrModel] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SynthesizeDataRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SynthesizeDataRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocExtractPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[SynthesizeDataRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        sheet_url : typing.Optional[core.File]
            See core.File for more documentation

        selected_asr_model : typing.Optional[SynthesizeDataRequestSelectedAsrModel]

        google_translate_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        task_instructions : typing.Optional[str]

        selected_model : typing.Optional[SynthesizeDataRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SynthesizeDataRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocExtractPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.synthesize_data()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/doc-extract/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_asr_model": selected_asr_model,
                "google_translate_target": google_translate_target,
                "task_instructions": task_instructions,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            files={
                "documents": documents,
                "sheet_url": sheet_url,
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocExtractPageOutput,
                    parse_obj_as(
                        type_=DocExtractPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def llm(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[CompareLlmPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_prompt: typing.Optional[str] = OMIT,
        selected_models: typing.Optional[typing.Sequence[CompareLlmPageRequestSelectedModelsItem]] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[CompareLlmPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareLlmPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[CompareLlmPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        selected_models : typing.Optional[typing.Sequence[CompareLlmPageRequestSelectedModelsItem]]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[CompareLlmPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareLlmPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.llm()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/CompareLLM/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "selected_models": selected_models,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareLlmPageOutput,
                    parse_obj_as(
                        type_=CompareLlmPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def rag(
        self,
        *,
        search_query: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[DocSearchPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        keyword_query: typing.Optional[DocSearchPageRequestKeywordQuery] = OMIT,
        documents: typing.Optional[typing.Sequence[str]] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        doc_extract_url: typing.Optional[str] = OMIT,
        embedding_model: typing.Optional[DocSearchPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[DocSearchPageRequestSelectedModel] = OMIT,
        citation_style: typing.Optional[DocSearchPageRequestCitationStyle] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[DocSearchPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocSearchPageOutput:
        """
        Parameters
        ----------
        search_query : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[DocSearchPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        keyword_query : typing.Optional[DocSearchPageRequestKeywordQuery]

        documents : typing.Optional[typing.Sequence[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        doc_extract_url : typing.Optional[str]

        embedding_model : typing.Optional[DocSearchPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[DocSearchPageRequestSelectedModel]

        citation_style : typing.Optional[DocSearchPageRequestCitationStyle]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[DocSearchPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocSearchPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.rag(
                search_query="search_query",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/doc-search/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "keyword_query": keyword_query,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "doc_extract_url": doc_extract_url,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "citation_style": citation_style,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocSearchPageOutput,
                    parse_obj_as(
                        type_=DocSearchPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def smart_gpt(
        self,
        *,
        input_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[SmartGptPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        cot_prompt: typing.Optional[str] = OMIT,
        reflexion_prompt: typing.Optional[str] = OMIT,
        dera_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SmartGptPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[SmartGptPageRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SmartGptPageOutput:
        """
        Parameters
        ----------
        input_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[SmartGptPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        cot_prompt : typing.Optional[str]

        reflexion_prompt : typing.Optional[str]

        dera_prompt : typing.Optional[str]

        selected_model : typing.Optional[SmartGptPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[SmartGptPageRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SmartGptPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.smart_gpt(
                input_prompt="input_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/SmartGPT/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "cot_prompt": cot_prompt,
                "reflexion_prompt": reflexion_prompt,
                "dera_prompt": dera_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SmartGptPageOutput,
                    parse_obj_as(
                        type_=SmartGptPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def doc_summary(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[DocSummaryRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        merge_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[DocSummaryRequestSelectedModel] = OMIT,
        chain_type: typing.Optional[typing.Literal["map_reduce"]] = OMIT,
        selected_asr_model: typing.Optional[DocSummaryRequestSelectedAsrModel] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[DocSummaryRequestResponseFormatType] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DocSummaryPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[DocSummaryRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        task_instructions : typing.Optional[str]

        merge_instructions : typing.Optional[str]

        selected_model : typing.Optional[DocSummaryRequestSelectedModel]

        chain_type : typing.Optional[typing.Literal["map_reduce"]]

        selected_asr_model : typing.Optional[DocSummaryRequestSelectedAsrModel]

        google_translate_target : typing.Optional[str]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[DocSummaryRequestResponseFormatType]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DocSummaryPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.doc_summary()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/doc-summary/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "task_instructions": task_instructions,
                "merge_instructions": merge_instructions,
                "selected_model": selected_model,
                "chain_type": chain_type,
                "selected_asr_model": selected_asr_model,
                "google_translate_target": google_translate_target,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "settings": settings,
            },
            files={
                "documents": documents,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DocSummaryPageOutput,
                    parse_obj_as(
                        type_=DocSummaryPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def functions(
        self,
        *,
        example_id: typing.Optional[str] = None,
        code: typing.Optional[str] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FunctionsPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        code : typing.Optional[str]
            The JS code to be executed.

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used in the code

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FunctionsPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.functions()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/functions/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "code": code,
                "variables": variables,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    FunctionsPageOutput,
                    parse_obj_as(
                        type_=FunctionsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def lipsync(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[LipsyncRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_face: typing.Optional[core.File] = OMIT,
        face_padding_top: typing.Optional[int] = OMIT,
        face_padding_bottom: typing.Optional[int] = OMIT,
        face_padding_left: typing.Optional[int] = OMIT,
        face_padding_right: typing.Optional[int] = OMIT,
        sadtalker_settings: typing.Optional[LipsyncRequestSadtalkerSettings] = OMIT,
        selected_model: typing.Optional[LipsyncRequestSelectedModel] = OMIT,
        input_audio: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LipsyncPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[LipsyncRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_face : typing.Optional[core.File]
            See core.File for more documentation

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[LipsyncRequestSadtalkerSettings]

        selected_model : typing.Optional[LipsyncRequestSelectedModel]

        input_audio : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LipsyncPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.lipsync()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/Lipsync/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "selected_model": selected_model,
                "settings": settings,
            },
            files={
                "input_face": input_face,
                "input_audio": input_audio,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    LipsyncPageOutput,
                    parse_obj_as(
                        type_=LipsyncPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def lipsync_tts(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[LipsyncTtsRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        tts_provider: typing.Optional[LipsyncTtsRequestTtsProvider] = OMIT,
        uberduck_voice_name: typing.Optional[str] = OMIT,
        uberduck_speaking_rate: typing.Optional[float] = OMIT,
        google_voice_name: typing.Optional[str] = OMIT,
        google_speaking_rate: typing.Optional[float] = OMIT,
        google_pitch: typing.Optional[float] = OMIT,
        bark_history_prompt: typing.Optional[str] = OMIT,
        elevenlabs_voice_name: typing.Optional[str] = OMIT,
        elevenlabs_api_key: typing.Optional[str] = OMIT,
        elevenlabs_voice_id: typing.Optional[str] = OMIT,
        elevenlabs_model: typing.Optional[str] = OMIT,
        elevenlabs_stability: typing.Optional[float] = OMIT,
        elevenlabs_similarity_boost: typing.Optional[float] = OMIT,
        elevenlabs_style: typing.Optional[float] = OMIT,
        elevenlabs_speaker_boost: typing.Optional[bool] = OMIT,
        azure_voice_name: typing.Optional[str] = OMIT,
        openai_voice_name: typing.Optional[LipsyncTtsRequestOpenaiVoiceName] = OMIT,
        openai_tts_model: typing.Optional[LipsyncTtsRequestOpenaiTtsModel] = OMIT,
        input_face: typing.Optional[core.File] = OMIT,
        face_padding_top: typing.Optional[int] = OMIT,
        face_padding_bottom: typing.Optional[int] = OMIT,
        face_padding_left: typing.Optional[int] = OMIT,
        face_padding_right: typing.Optional[int] = OMIT,
        sadtalker_settings: typing.Optional[LipsyncTtsRequestSadtalkerSettings] = OMIT,
        selected_model: typing.Optional[LipsyncTtsRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LipsyncTtsPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[LipsyncTtsRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        tts_provider : typing.Optional[LipsyncTtsRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[LipsyncTtsRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[LipsyncTtsRequestOpenaiTtsModel]

        input_face : typing.Optional[core.File]
            See core.File for more documentation

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[LipsyncTtsRequestSadtalkerSettings]

        selected_model : typing.Optional[LipsyncTtsRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LipsyncTtsPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.lipsync_tts(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/LipsyncTTS/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "selected_model": selected_model,
                "settings": settings,
            },
            files={
                "input_face": input_face,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    LipsyncTtsPageOutput,
                    parse_obj_as(
                        type_=LipsyncTtsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def text_to_speech(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[TextToSpeechPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        tts_provider: typing.Optional[TextToSpeechPageRequestTtsProvider] = OMIT,
        uberduck_voice_name: typing.Optional[str] = OMIT,
        uberduck_speaking_rate: typing.Optional[float] = OMIT,
        google_voice_name: typing.Optional[str] = OMIT,
        google_speaking_rate: typing.Optional[float] = OMIT,
        google_pitch: typing.Optional[float] = OMIT,
        bark_history_prompt: typing.Optional[str] = OMIT,
        elevenlabs_voice_name: typing.Optional[str] = OMIT,
        elevenlabs_api_key: typing.Optional[str] = OMIT,
        elevenlabs_voice_id: typing.Optional[str] = OMIT,
        elevenlabs_model: typing.Optional[str] = OMIT,
        elevenlabs_stability: typing.Optional[float] = OMIT,
        elevenlabs_similarity_boost: typing.Optional[float] = OMIT,
        elevenlabs_style: typing.Optional[float] = OMIT,
        elevenlabs_speaker_boost: typing.Optional[bool] = OMIT,
        azure_voice_name: typing.Optional[str] = OMIT,
        openai_voice_name: typing.Optional[TextToSpeechPageRequestOpenaiVoiceName] = OMIT,
        openai_tts_model: typing.Optional[TextToSpeechPageRequestOpenaiTtsModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TextToSpeechPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[TextToSpeechPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        tts_provider : typing.Optional[TextToSpeechPageRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[TextToSpeechPageRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[TextToSpeechPageRequestOpenaiTtsModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TextToSpeechPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.text_to_speech(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/TextToSpeech/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    TextToSpeechPageOutput,
                    parse_obj_as(
                        type_=TextToSpeechPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def speech_recognition(
        self,
        *,
        documents: typing.List[core.File],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[SpeechRecognitionRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[SpeechRecognitionRequestSelectedModel] = OMIT,
        language: typing.Optional[str] = OMIT,
        translation_model: typing.Optional[SpeechRecognitionRequestTranslationModel] = OMIT,
        output_format: typing.Optional[SpeechRecognitionRequestOutputFormat] = OMIT,
        google_translate_target: typing.Optional[str] = OMIT,
        translation_source: typing.Optional[str] = OMIT,
        translation_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsrPageOutput:
        """
        Parameters
        ----------
        documents : typing.List[core.File]
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[SpeechRecognitionRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[SpeechRecognitionRequestSelectedModel]

        language : typing.Optional[str]

        translation_model : typing.Optional[SpeechRecognitionRequestTranslationModel]

        output_format : typing.Optional[SpeechRecognitionRequestOutputFormat]

        google_translate_target : typing.Optional[str]
            use `translation_model` & `translation_target` instead.

        translation_source : typing.Optional[str]

        translation_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsrPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.speech_recognition()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/asr/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_model": selected_model,
                "language": language,
                "translation_model": translation_model,
                "output_format": output_format,
                "google_translate_target": google_translate_target,
                "translation_source": translation_source,
                "translation_target": translation_target,
                "settings": settings,
            },
            files={
                "documents": documents,
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    AsrPageOutput,
                    parse_obj_as(
                        type_=AsrPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def text_to_music(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[Text2AudioPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        duration_sec: typing.Optional[float] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        selected_models: typing.Optional[typing.Sequence[typing.Literal["audio_ldm"]]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Text2AudioPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[Text2AudioPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        negative_prompt : typing.Optional[str]

        duration_sec : typing.Optional[float]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        sd2upscaling : typing.Optional[bool]

        selected_models : typing.Optional[typing.Sequence[typing.Literal["audio_ldm"]]]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Text2AudioPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.text_to_music(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/text2audio/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "duration_sec": duration_sec,
                "num_outputs": num_outputs,
                "quality": quality,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "sd_2_upscaling": sd2upscaling,
                "selected_models": selected_models,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Text2AudioPageOutput,
                    parse_obj_as(
                        type_=Text2AudioPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def translate(
        self,
        *,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[TranslateRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        texts: typing.Optional[typing.List[str]] = OMIT,
        selected_model: typing.Optional[TranslateRequestSelectedModel] = OMIT,
        translation_source: typing.Optional[str] = OMIT,
        translation_target: typing.Optional[str] = OMIT,
        glossary_document: typing.Optional[core.File] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranslationPageOutput:
        """
        Parameters
        ----------
        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[TranslateRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        texts : typing.Optional[typing.List[str]]

        selected_model : typing.Optional[TranslateRequestSelectedModel]

        translation_source : typing.Optional[str]

        translation_target : typing.Optional[str]

        glossary_document : typing.Optional[core.File]
            See core.File for more documentation

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranslationPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.translate()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/translate/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "translation_source": translation_source,
                "translation_target": translation_target,
                "settings": settings,
            },
            files={
                "glossary_document": glossary_document,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    TranslationPageOutput,
                    parse_obj_as(
                        type_=TranslationPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def remix_image(
        self,
        *,
        input_image: core.File,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[RemixImageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        text_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RemixImageRequestSelectedModel] = OMIT,
        selected_controlnet_model: typing.Optional[RemixImageRequestSelectedControlnetModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        prompt_strength: typing.Optional[float] = OMIT,
        controlnet_conditioning_scale: typing.Optional[typing.List[float]] = OMIT,
        seed: typing.Optional[int] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Img2ImgPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[RemixImageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        text_prompt : typing.Optional[str]

        selected_model : typing.Optional[RemixImageRequestSelectedModel]

        selected_controlnet_model : typing.Optional[RemixImageRequestSelectedControlnetModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        prompt_strength : typing.Optional[float]

        controlnet_conditioning_scale : typing.Optional[typing.List[float]]

        seed : typing.Optional[int]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Img2ImgPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.remix_image()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/Img2Img/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "selected_model": selected_model,
                "selected_controlnet_model": selected_controlnet_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "prompt_strength": prompt_strength,
                "controlnet_conditioning_scale": controlnet_conditioning_scale,
                "seed": seed,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Img2ImgPageOutput,
                    parse_obj_as(
                        type_=Img2ImgPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def text_to_image(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[CompareText2ImgPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        dall_e3quality: typing.Optional[str] = OMIT,
        dall_e3style: typing.Optional[str] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        selected_models: typing.Optional[typing.Sequence[CompareText2ImgPageRequestSelectedModelsItem]] = OMIT,
        scheduler: typing.Optional[CompareText2ImgPageRequestScheduler] = OMIT,
        edit_instruction: typing.Optional[str] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareText2ImgPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[CompareText2ImgPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        negative_prompt : typing.Optional[str]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        dall_e3quality : typing.Optional[str]

        dall_e3style : typing.Optional[str]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        sd2upscaling : typing.Optional[bool]

        selected_models : typing.Optional[typing.Sequence[CompareText2ImgPageRequestSelectedModelsItem]]

        scheduler : typing.Optional[CompareText2ImgPageRequestScheduler]

        edit_instruction : typing.Optional[str]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareText2ImgPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.text_to_image(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/CompareText2Img/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "negative_prompt": negative_prompt,
                "output_width": output_width,
                "output_height": output_height,
                "num_outputs": num_outputs,
                "quality": quality,
                "dall_e_3_quality": dall_e3quality,
                "dall_e_3_style": dall_e3style,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "sd_2_upscaling": sd2upscaling,
                "selected_models": selected_models,
                "scheduler": scheduler,
                "edit_instruction": edit_instruction,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareText2ImgPageOutput,
                    parse_obj_as(
                        type_=CompareText2ImgPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def product_image(
        self,
        *,
        input_image: core.File,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[ProductImageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        mask_threshold: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[ProductImageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ObjectInpaintingPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[ProductImageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        mask_threshold : typing.Optional[float]

        selected_model : typing.Optional[ProductImageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        sd2upscaling : typing.Optional[bool]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ObjectInpaintingPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.product_image(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/ObjectInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "mask_threshold": mask_threshold,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "sd_2_upscaling": sd2upscaling,
                "seed": seed,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ObjectInpaintingPageOutput,
                    parse_obj_as(
                        type_=ObjectInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def portrait(
        self,
        *,
        input_image: core.File,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[PortraitRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        face_scale: typing.Optional[float] = OMIT,
        face_pos_x: typing.Optional[float] = OMIT,
        face_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[PortraitRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        upscale_factor: typing.Optional[float] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FaceInpaintingPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[PortraitRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        face_scale : typing.Optional[float]

        face_pos_x : typing.Optional[float]

        face_pos_y : typing.Optional[float]

        selected_model : typing.Optional[PortraitRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        upscale_factor : typing.Optional[float]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FaceInpaintingPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.portrait(
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/FaceInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "text_prompt": text_prompt,
                "face_scale": face_scale,
                "face_pos_x": face_pos_x,
                "face_pos_y": face_pos_y,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "upscale_factor": upscale_factor,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "seed": seed,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    FaceInpaintingPageOutput,
                    parse_obj_as(
                        type_=FaceInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def image_from_email(
        self,
        *,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[EmailFaceInpaintingPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        email_address: typing.Optional[str] = OMIT,
        twitter_handle: typing.Optional[str] = OMIT,
        face_scale: typing.Optional[float] = OMIT,
        face_pos_x: typing.Optional[float] = OMIT,
        face_pos_y: typing.Optional[float] = OMIT,
        selected_model: typing.Optional[EmailFaceInpaintingPageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        upscale_factor: typing.Optional[float] = OMIT,
        output_width: typing.Optional[int] = OMIT,
        output_height: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        should_send_email: typing.Optional[bool] = OMIT,
        email_from: typing.Optional[str] = OMIT,
        email_cc: typing.Optional[str] = OMIT,
        email_bcc: typing.Optional[str] = OMIT,
        email_subject: typing.Optional[str] = OMIT,
        email_body: typing.Optional[str] = OMIT,
        email_body_enable_html: typing.Optional[bool] = OMIT,
        fallback_email_body: typing.Optional[str] = OMIT,
        seed: typing.Optional[int] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmailFaceInpaintingPageOutput:
        """
        Parameters
        ----------
        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[EmailFaceInpaintingPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        email_address : typing.Optional[str]

        twitter_handle : typing.Optional[str]

        face_scale : typing.Optional[float]

        face_pos_x : typing.Optional[float]

        face_pos_y : typing.Optional[float]

        selected_model : typing.Optional[EmailFaceInpaintingPageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        upscale_factor : typing.Optional[float]

        output_width : typing.Optional[int]

        output_height : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        should_send_email : typing.Optional[bool]

        email_from : typing.Optional[str]

        email_cc : typing.Optional[str]

        email_bcc : typing.Optional[str]

        email_subject : typing.Optional[str]

        email_body : typing.Optional[str]

        email_body_enable_html : typing.Optional[bool]

        fallback_email_body : typing.Optional[str]

        seed : typing.Optional[int]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmailFaceInpaintingPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.image_from_email(
                email_address="sean@dara.network",
                text_prompt="winter's day in paris",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/EmailFaceInpainting/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "email_address": email_address,
                "twitter_handle": twitter_handle,
                "text_prompt": text_prompt,
                "face_scale": face_scale,
                "face_pos_x": face_pos_x,
                "face_pos_y": face_pos_y,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "upscale_factor": upscale_factor,
                "output_width": output_width,
                "output_height": output_height,
                "guidance_scale": guidance_scale,
                "should_send_email": should_send_email,
                "email_from": email_from,
                "email_cc": email_cc,
                "email_bcc": email_bcc,
                "email_subject": email_subject,
                "email_body": email_body,
                "email_body_enable_html": email_body_enable_html,
                "fallback_email_body": fallback_email_body,
                "seed": seed,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmailFaceInpaintingPageOutput,
                    parse_obj_as(
                        type_=EmailFaceInpaintingPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def image_from_web_search(
        self,
        *,
        search_query: str,
        text_prompt: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[GoogleImageGenPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        selected_model: typing.Optional[GoogleImageGenPageRequestSelectedModel] = OMIT,
        negative_prompt: typing.Optional[str] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[int] = OMIT,
        guidance_scale: typing.Optional[float] = OMIT,
        prompt_strength: typing.Optional[float] = OMIT,
        sd2upscaling: typing.Optional[bool] = OMIT,
        seed: typing.Optional[int] = OMIT,
        image_guidance_scale: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GoogleImageGenPageOutput:
        """
        Parameters
        ----------
        search_query : str

        text_prompt : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[GoogleImageGenPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        selected_model : typing.Optional[GoogleImageGenPageRequestSelectedModel]

        negative_prompt : typing.Optional[str]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[int]

        guidance_scale : typing.Optional[float]

        prompt_strength : typing.Optional[float]

        sd2upscaling : typing.Optional[bool]

        seed : typing.Optional[int]

        image_guidance_scale : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GoogleImageGenPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.image_from_web_search(
                search_query="search_query",
                text_prompt="text_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/GoogleImageGen/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "search_query": search_query,
                "text_prompt": text_prompt,
                "selected_model": selected_model,
                "negative_prompt": negative_prompt,
                "num_outputs": num_outputs,
                "quality": quality,
                "guidance_scale": guidance_scale,
                "prompt_strength": prompt_strength,
                "sd_2_upscaling": sd2upscaling,
                "seed": seed,
                "image_guidance_scale": image_guidance_scale,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    GoogleImageGenPageOutput,
                    parse_obj_as(
                        type_=GoogleImageGenPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def remove_background(
        self,
        *,
        input_image: core.File,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[RemoveBackgroundRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[RemoveBackgroundRequestSelectedModel] = OMIT,
        mask_threshold: typing.Optional[float] = OMIT,
        rect_persepective_transform: typing.Optional[bool] = OMIT,
        reflection_opacity: typing.Optional[float] = OMIT,
        obj_scale: typing.Optional[float] = OMIT,
        obj_pos_x: typing.Optional[float] = OMIT,
        obj_pos_y: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ImageSegmentationPageOutput:
        """
        Parameters
        ----------
        input_image : core.File
            See core.File for more documentation

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[RemoveBackgroundRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[RemoveBackgroundRequestSelectedModel]

        mask_threshold : typing.Optional[float]

        rect_persepective_transform : typing.Optional[bool]

        reflection_opacity : typing.Optional[float]

        obj_scale : typing.Optional[float]

        obj_pos_x : typing.Optional[float]

        obj_pos_y : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ImageSegmentationPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.remove_background()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/ImageSegmentation/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "selected_model": selected_model,
                "mask_threshold": mask_threshold,
                "rect_persepective_transform": rect_persepective_transform,
                "reflection_opacity": reflection_opacity,
                "obj_scale": obj_scale,
                "obj_pos_x": obj_pos_x,
                "obj_pos_y": obj_pos_y,
                "settings": settings,
            },
            files={
                "input_image": input_image,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ImageSegmentationPageOutput,
                    parse_obj_as(
                        type_=ImageSegmentationPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upscale(
        self,
        *,
        scale: int,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.List[UpscaleRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        input_image: typing.Optional[core.File] = OMIT,
        input_video: typing.Optional[core.File] = OMIT,
        selected_models: typing.Optional[typing.List[UpscaleRequestSelectedModelsItem]] = OMIT,
        selected_bg_model: typing.Optional[typing.Literal["real_esrgan_x2"]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CompareUpscalerPageOutput:
        """
        Parameters
        ----------
        scale : int
            The final upsampling scale of the image

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.List[UpscaleRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_image : typing.Optional[core.File]
            See core.File for more documentation

        input_video : typing.Optional[core.File]
            See core.File for more documentation

        selected_models : typing.Optional[typing.List[UpscaleRequestSelectedModelsItem]]

        selected_bg_model : typing.Optional[typing.Literal["real_esrgan_x2"]]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CompareUpscalerPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.upscale(
                scale=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/compare-ai-upscalers/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            data={
                "functions": functions,
                "variables": variables,
                "scale": scale,
                "selected_models": selected_models,
                "selected_bg_model": selected_bg_model,
                "settings": settings,
            },
            files={
                "input_image": input_image,
                "input_video": input_video,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CompareUpscalerPageOutput,
                    parse_obj_as(
                        type_=CompareUpscalerPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def embed(
        self,
        *,
        texts: typing.Sequence[str],
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[EmbeddingsPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        selected_model: typing.Optional[EmbeddingsPageRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmbeddingsPageOutput:
        """
        Parameters
        ----------
        texts : typing.Sequence[str]

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[EmbeddingsPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[EmbeddingsPageRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingsPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.embed(
                texts=["texts"],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/embeddings/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmbeddingsPageOutput,
                    parse_obj_as(
                        type_=EmbeddingsPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def seo_people_also_ask_doc(
        self,
        *,
        search_query: str,
        example_id: typing.Optional[str] = None,
        functions: typing.Optional[typing.Sequence[RelatedQnADocPageRequestFunctionsItem]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        keyword_query: typing.Optional[RelatedQnADocPageRequestKeywordQuery] = OMIT,
        documents: typing.Optional[typing.Sequence[str]] = OMIT,
        max_references: typing.Optional[int] = OMIT,
        max_context_words: typing.Optional[int] = OMIT,
        scroll_jump: typing.Optional[int] = OMIT,
        doc_extract_url: typing.Optional[str] = OMIT,
        embedding_model: typing.Optional[RelatedQnADocPageRequestEmbeddingModel] = OMIT,
        dense_weight: typing.Optional[float] = OMIT,
        task_instructions: typing.Optional[str] = OMIT,
        query_instructions: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[RelatedQnADocPageRequestSelectedModel] = OMIT,
        citation_style: typing.Optional[RelatedQnADocPageRequestCitationStyle] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        response_format_type: typing.Optional[RelatedQnADocPageRequestResponseFormatType] = OMIT,
        serp_search_location: typing.Optional[SerpSearchLocation] = OMIT,
        scaleserp_locations: typing.Optional[typing.Sequence[str]] = OMIT,
        serp_search_type: typing.Optional[SerpSearchType] = OMIT,
        scaleserp_search_field: typing.Optional[str] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RelatedQnADocPageOutput:
        """
        Parameters
        ----------
        search_query : str

        example_id : typing.Optional[str]

        functions : typing.Optional[typing.Sequence[RelatedQnADocPageRequestFunctionsItem]]

        variables : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        keyword_query : typing.Optional[RelatedQnADocPageRequestKeywordQuery]

        documents : typing.Optional[typing.Sequence[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        doc_extract_url : typing.Optional[str]

        embedding_model : typing.Optional[RelatedQnADocPageRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        selected_model : typing.Optional[RelatedQnADocPageRequestSelectedModel]

        citation_style : typing.Optional[RelatedQnADocPageRequestCitationStyle]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[RelatedQnADocPageRequestResponseFormatType]

        serp_search_location : typing.Optional[SerpSearchLocation]

        scaleserp_locations : typing.Optional[typing.Sequence[str]]
            DEPRECATED: use `serp_search_location` instead

        serp_search_type : typing.Optional[SerpSearchType]

        scaleserp_search_field : typing.Optional[str]
            DEPRECATED: use `serp_search_type` instead

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RelatedQnADocPageOutput
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.seo_people_also_ask_doc(
                search_query="search_query",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/related-qna-maker-doc/async",
            method="POST",
            params={
                "example_id": example_id,
            },
            json={
                "functions": functions,
                "variables": variables,
                "search_query": search_query,
                "keyword_query": keyword_query,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "doc_extract_url": doc_extract_url,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "selected_model": selected_model,
                "citation_style": citation_style,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "serp_search_location": serp_search_location,
                "scaleserp_locations": scaleserp_locations,
                "serp_search_type": serp_search_type,
                "scaleserp_search_field": scaleserp_search_field,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RelatedQnADocPageOutput,
                    parse_obj_as(
                        type_=RelatedQnADocPageOutput,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        GenericErrorResponse,
                        parse_obj_as(
                            type_=GenericErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_balance(self, *, request_options: typing.Optional[RequestOptions] = None) -> BalanceResponse:
        """
        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BalanceResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.get_balance()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v1/balance/",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    BalanceResponse,
                    parse_obj_as(
                        type_=BalanceResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


def _get_base_url(*, base_url: typing.Optional[str] = None, environment: GooeyEnvironment) -> str:
    if base_url is not None:
        return base_url
    elif environment is not None:
        return environment.value
    else:
        raise Exception("Please pass in either base_url or environment to construct the client")
