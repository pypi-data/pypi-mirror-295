{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Inference of Mass Eruption Rate from a single observation of Plume Height\n\nIn this example, we illustrate how MERPH can be used to generate plausible estimates of the Mass Eruption Rate (MER) from an observation of the plume height (H) using Mastin's data set.\n\nWe will import the data and take a quick look at it.  We will then specify the independent (explanatory) and dependent (output) variables, and set an observation.  Estimates will be generated by drawing samples from the posterior predictive distribution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This example can be viewed as a Jupyter notebook, launched from the commandline using `merph --example 1` or from an interactive python session using\n\n```python\nimport merph\nmerph.launch_jupyter_example(1)</p></div>\n```\n## Imports\n\nFirst, we import MERPH package (and matplotlib for plotting)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nimport merph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory data analysis\n\nThe MERPH packages includes four data sets; those of Sparks, Mastin, and Aubry, and the IVESPA data.  Here we will use Mastin's data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Mastin = merph.load_Mastin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The object `Mastin` is an instance of the `Merph` class within merph.  We can learn about it by printing:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(Mastin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Merph` object, `Mastin`, contains the data in the Mastin dataset and methods to perform statistical analysis on this data.\n\nWe can view the data set as a pandas dataframe using `Mastin.data`.  Additionally, methods for the pandas dataframe can be called.  For example, we can plot the data using tools from `pandas.DataFrame.plot`.\n\nAs an example, we can produce a scatter plot the mass eruption rate (contained in the 'MER' column of the dataframe) and the plume height (contained in the 'Plume height' column):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = Mastin.data.plot.scatter(x='MER', y='Plume height')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interesting... but the linear scale for the MER-axis is not helping here.  Perhaps we should re-plot with a logarithmic scale for MER:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = Mastin.data.plot.scatter(x='MER', y='Plume height', logx=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now a very clear relationship appears.  The plume height increases with the MER, and it looks like a power-law relationship would describe this, i.e. $H = a \\times Q^{b}$ for some values of $a$ and $b$.\n\nThis power-law relationship is expected from dimensional reasoning and from theoretical analysis of the fluid mechanics for turbulent plumes.\n\nWe can find the values of $a$ and $b$ using linear regression of logarithmically transformed data.  Taking logarithms we find a linear relationship, $\\log H = \\log a + b\\log Q$, so finding the slope and intercept of the data on a log-log plot would give a prediction of connection between plume height and mass eruption rate.  (The plot below shows Mastin's data on log-log scales, and a straight-line fit looks like it would be reasonable.)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = Mastin.data.plot.scatter(x='MER', y='Plume height', logx=True, logy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In MERPH, we use the logarithmic transformation of the data to look for the relationship between the plume height and mass eruption rate.  For the Mastin data loaded with `merph.load_Mastin()`, the columns in the dataframe corresponding the plume height and mass eruption rate have been assigned, and can be found using `height_column` and `mer_column`` attributes of the `Merph`</code>` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"MER data is in the column called '{Mastin.mer_column}'\")\nprint(f\"Plume height data is in the column called '{Mastin.height_column}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear regression by maximum likelihood estimation\n\nTo perform regression analysis using the Mastin data, we need to specify the 'explanatory' (independent) and 'response' (dependent) variables.  These are often labelled as the $x$ and $y$ variables, and we use this in merph for simplicity.\n\nMost commonly we will want to predict the mass eruption rate from an observation of the plume height.  Thus, we have the $x$ variable as logarithm of the plume height ($x = \\log_{10} H$), and the $y$ variable as the logarithm of the mass eruption rate ($y = \\log_{10} Q$).\n\nWe specify this for the `Merph` object using the `set_vars` method, where we specify `xvar` and `yvar` as either `'H'` for plume height or `'Q'` (or `'MER'`) for the mass eruption rate.\n\nHere we want plume height (`'H'`) to be the explanatory variable, and predict the mass eruption rate (`'Q'`) from it, so we specify:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Mastin.set_vars(xvar='H', yvar='Q')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then proceed to perform the linear regression of the log-transformed data.  In merph this is done using maximum likelihood estimation, implemented automatically when the variables are set.\n\nThis produces the posterior distribution for the model parameters.\n\nWe can visualize this using the `plot` method of the `posterior` subclass.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 6\nfig, ax = Mastin.posterior.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The maximum likelihood estimator of the linear regression coefficients in the log-log space produces a nice fit, and gives a good fit of the data in the semi-log space.\n\n## Bayesian linear regression\n\nWhile the linear regression fits the trend of the data, there remains considerable scatter around the curve.  The amount of scatter can be substantial.  For example, for a plume height of around 10 km, the data spans mass eruption rates between $\\sim 5\\times 10^{5}$ and $\\sim 5\\times 10^{7}$ -- two orders of magnitude.\n\nTo make meaningful inference of the mass eruption rate from the plume height, it is important to consider the scatter.  With maximum likelihood estimation, we can provide confidence intervals, but a Bayesian approach to linear regression provides other advantages.\n\nIn Bayesian linear regression, we propose a model\n\n\\begin{align}y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i},\\end{align}\n\n(recalling $y_{i}=\\log_{10} Q_{i}$, $x_{i} = \\log_{10} H_{i}$, so $Q=10^{\\beta_{0}} H^{\\beta_{1}}$) where $\\epsilon_{i}$ is a model error term that is included to account for deviation from the straight-line fit.  If we assume the errors are independent and identically distributed, then the error can be modelled as $\\epsilon_{i} \\sim N(0, \\sigma^{2})$, with a constant variance $\\sigma^{2}$.  Our goal is to determine the model parameters $\\mathbf{\\beta} = (\\beta_{0},\\beta_{1})$ and $\\sigma^{2}$.\n\nIn Bayesian linear regression, we specify priors on the model parameters, and it is common to take a non-informative prior of the form\n\n\\begin{align}p(\\mathbf{\\beta},\\sigma^{2}) \\propto 1/\\sigma^{2}.\\end{align}\n\nPosterior distributions for the model parameters are found using Bayes' theorem, using the data and prior.\n\nIn merph, the inference of the model parameters is performed when the variables are specified (i.e. when the `set_vars()` method is called for a dataset).\n\nThe posterior distributions can be explored using the methods in the `posterior` subclass.  Perhaps the most useful is the visualization of curve fits obtained from sampling the posterior distributions:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = Mastin.posterior.plot(samples=1000,interval=[0.9,0.95,0.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we have sampled 1000 plausible line fits from the posterior distribution, and plotted these together with three credible intervals (at the 90%, 95% and 99% levels), the mean curve and the data.\n\nWe can use these to make predictions of the response variable given an observation of the explanatory variable while accounting for the uncertainty in the dataset.  This is known as *Bayesian posterior prediction*.\n\n## Bayesian posterior prediction for mass eruption rate\n\nThe posterior predictive distribution can be visualized using the method `posterior_plot()` on the `Merph` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = Mastin.predictive_plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we see the observed data and the regression curve found by maximum likelihood estimation.  Additionally, for each plume height, we determine the posterior predictive distribution of the mass eruption rate, and plot prediction intervals.  The contours provide an appropriate envelope of the observations, illustrating the statistical model is appropriate.\n\nSuppose we have an observation of the plume height (in this example taken to be precise) of $H = 10$ km.  We can make predictions of the MER from the model using the `posterior_predictive` subclass, specifing this observation.  Here we store this in an instance of the subclass called `pred`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred = Mastin.posterior_predictive([10,20.])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important::\n\n    The observation here is given in the units of the data (in this case, height in km).  It is possible to use log-transformed values by passing the optional argument `logscale=True` to `posterior_predictive`  \n\n    This will then produce predictions for the response variable as log-transformed values.\n\n\nWe can then draw an estimate of the mass eruption rate from the posterior predictive distribution using the `simulate()` method of the `pred` object.  This produces a DataFrame with the observation and samples of the response variable, as well as the logarithm of these (which are used directly in the statistical model).  To draw five samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.simulate(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>As the samples are determined stochastically, the values obtained will be different each time `simulate` is called.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The DataFrame has ten rows as `simulate(5)` computes five samples for each of the discrete observations passed to `posterior_predictive` (here there are two observed heights).</p></div>\n\nRunning `pred.simulate()` again will produce a different estimate, as we draw model parameters (including the error term) from their posterior distributions.\n\nPassing the option `plot=True` to `posterior_predictive` creates a histogram of the posterior predictions.  Here we draw 1000 samples and view the histogram.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "posterior_samples = pred.simulate(1000, plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot shows histogram two histograms for the posterior predictive samples.\n\n The `posterior_predictive` subclass also contains methods that determine other useful quantities from the posterior predictive distribution. \n\n Here we illustrate them using the `pred` instance.\n\n- `pred.rvs(N)` draws `N` samples from the posterior predictive distribution, returning a numpy array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.rvs(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.pdf(Q)` computes the probability density of $Q|H$, returning a numpy array.  The argument `Q` can be a single value or an array of values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.pdf([1e6,5e6,1e7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important::\n\n        The posterior probability densities integrate to one, so the pdf at values of the MER are small, since the MER varies over several orders of magnitude.\n\n- `pred.cdf(Q)` computes the cumulative density probability of $Q|H$ returning a numpy array.  This is the probability $P(MER < Q | H)$.  The argument `Q` can be a single value or an array of values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.cdf([1e6,5e6,1e7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The cdf can be used to find the probability that the response variable takes values in a range.\n\n        Denoting the posterior predictive cdf as $F_{Q|H}(q) = P(Q\\leq q|H)$ we have\n\n            .. math::\n\n                P(q_{0}\\leq Q \\leq q_{1} | H) = F_{Q|H}(q_{1}) - F_{Q|H}(q_{0})</p></div>\n\n- `pred.sf(Q)` computes the survival function probability of $Q|H$, returning a numpy array.  This is the probability $P(MER > Q | H)$.  The argument `Q` can be a single value or an array of values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.sf([1e6,5e6,1e7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The survival function gives $P(Q\\geq q|H) = 1 - F_{Q|H}(q)$.</p></div>\n\n- `pred.ppf(alpha)` computes the probability point function of $Q|H$, returning a numpy array. The argument alpha can be a single value or an array of values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.ppf([0.75, 0.9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The probability point function is the inverse of the cumulative distribution function, so allows us to find the value $Q$ such that $P(MER \\leq Q | H) = \\alpha$.\n\n    As an example, we can compute the median by setting $\\alpha = 0.5$</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The median of the posterior predictive distribution for MER | H = {pred.obs[0]} km is {pred.ppf(0.5)[0][0]:.2e} kg/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.isf(alpha)` computes the inverse survival function of $Q|H$, returning a numpy array. The argument alpha can be a single value or an array of values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred.isf([0.75, 0.9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The inverse survival function allows us to find the value $Q$ such that $P(MER \\geq Q | H) = \\alpha$.\n\n    As an example, we can compute the median by setting $\\alpha = 0.5$</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The median of the posterior predictive distribution for MER | H = {pred.obs[0]} km is {pred.isf(0.5)[0][0]:.2e} kg/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.median()` computes the median of the posterior predictive distribution, returning a numpy array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The median of the posterior predictive distribution for MER | H = {pred.obs[0]} km is {pred.median()[0]:.2e} kg/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.mean()` computes the mean of the posterior predictive distribution, returning a numpy array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The mean of the posterior predictive distribution for log MER | H = {pred.obs[0]} km is {pred.mean()[0]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.std()` computes the standard deviation of the posterior predictive distribution, returning a numpy array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The standard deviation of the posterior predictive distribution for log MER | H = {pred.obs[0]} km is {pred.std()[0]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `pred.var()` computes the variance of the posterior predictive distribution, returning a numpy array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The variance of the posterior predictive distribution for log MER | H = {pred.obs[0]} km is {pred.var()[0]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important::\n\n        The mean, standard deviation and variance of the posterior distribution function are only defined in log-space.  The results are therefore in log-space.\n\n- `pred.interval(alpha)` computes credible intervals with equal areas around the median of the posterior predictive distribution, returning a numpy array.  As an example, a 95% credible prediction interval can be computed by setting $\\alpha = 0.95$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intervals = pred.interval(0.95)[0,:,:]\nprint(f\"The 95% credible interval for MER | H = {pred.obs[0]} km is [{intervals[0,0]:.2e},{intervals[1,0]:.2e}] kg/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is also a `plot` subclass of `posterior_predictive` that produces plots from some of the quantities.  The use is illustrated below.\n\nThe posterior predictive density can be plotted using `plot.pdf()`, returning a Figure and Axes instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = pred.plot.pdf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior predictive cumulative density can be plotted using `plot.cdf()`, returning a Figure and Axes instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = pred.plot.cdf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior predictive probability point function can be plotted using `plot.ppf()`, returning a Figure and Axes instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = pred.plot.ppf()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}