Metadata-Version: 2.1
Name: PTransformer
Version: 0.0.1.2
Summary: This is Ai Transformer
Author: ProgramerSalar
Author-email: <manishkumar60708090@gmail.com>
Keywords: python,transformer,chat-GPT Transformer
Classifier: Development Status :: 1 - Planning
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Description-Content-Type: text/markdown
Requires-Dist: torch


# This is Transformer 




- if you are import the model of the Transformer then used to this import 
```
# import the transformer model 
>>> from GorparTansformer.model import build_transformer

# how to used this transformer model 
>>> build_transformer(
        vocab_src_len=vocabulary_source_length,   # vocabulary source length of sentence like tokeinzer source length of 
        vocab_tgt_len=vocabulary_target_length,    # same for the target language 
        src_seq_len=config["seq_len"],     # source language  length of you sentence like 350 
        tgt_seq_len=config['seq_len'],     # target language length of you sentence same as source length
        d_model=config['d_model']        # dimension model your language like 512
)
```




- if you import the Tensor dataset function, which is convert the tensor data from raw data 
```
# import the Tensor dataset Function
>>> from GorparTansformer.dataset import BilingualDataset

# how to used this Tensor dataset which is convert to the Tensor of the row data 
>>> BilingualDataset(
        ds=train_dataset_raw,   # raw dataset like='Ram eats mango'
        tokenizer_src=tokenizer_source,  # source language tokenizer 
        tokenizer_tgt=tokinzer_target,   # target language tokenizer
        src_lang=config['lang_src'],      # source language like engish
        tgt_lang=config['lang_tgt'],     # target language like Hindi
        seq_len=config['seq_len'])      # sequence length like 350
```


