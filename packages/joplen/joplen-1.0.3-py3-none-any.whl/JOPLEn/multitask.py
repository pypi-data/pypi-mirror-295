from __future__ import annotations

from collections import defaultdict
from datetime import datetime
from typing import Callable, Sequence

import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpy as np
from matplotlib import pyplot as plt
from numpy.random import RandomState
from sklearn.exceptions import NotFittedError
from sklearn.metrics import root_mean_squared_error
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

from .enums import DTYPE, LossType, NormType
from .partitioner import Partitioner, VPartition, numpify
from .proj_l1_ball import euclidean_proj_l1ball
from .st_loss import LogisticLoss, SquaredError


def core_l21_prox(
    v: jnp.ndarray,
    lam: float,
) -> jnp.ndarray:
    """Compute the proximal operator of the l2,1 norm.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).
        lam (float): The regularization parameter.

    Returns:
        jnp.ndarray: The proximal operator of the l2,1 norm.
    """
    norm = jnp.linalg.norm(v, axis=(0, 2), keepdims=True, ord="fro")
    return jnp.maximum(1 - lam / norm, 0) * v


def task_l21_prox(
    v: jnp.ndarray,
    lam: float,
) -> jnp.ndarray:
    """Compute the proximal operator of the l2,1 norm.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).
        lam (float): The regularization parameter.

    Returns:
        jnp.ndarray: The proximal operator of the l2,1 norm.
    """
    norm = jnp.linalg.norm(v, axis=2, keepdims=True, ord=2)
    return jnp.maximum(1 - lam / norm, 0) * v


def core_l21_norm(
    v: jnp.ndarray,
) -> float:
    """Compute the l2,1 norm where the 2 norm is computed over all cells and tasks.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).
        lam (float): The regularization parameter.

    Returns:
        float: The l2,1 norm.
    """
    return jnp.linalg.norm(v, axis=(0, 2), ord="fro").reshape(-1)


def task_l21_norm(
    v: jnp.ndarray,
) -> jnp.ndarray:
    """Compute the l2,1 norm where the 2 norm is computed over all cells and tasks.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions
        lam (float): The regularization parameter.

    Returns:
        float: The l2,1 norm.
    """
    return jnp.linalg.norm(v, axis=-1, ord=2)


def sq_fnorm(v: jnp.ndarray) -> float:
    """Compute the squared frobenius norm of the input vector.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions * n_cells).

    Returns:
        float: The squared frobenius norm.
    """
    return float(jnp.sum(v**2))


def task_linf1_prox(
    v: jnp.ndarray,
    lam: float,
) -> jnp.ndarray:
    """Compute the linf,1 proximal operator, where the inf norm is computed over
        all cells and each task invidivually.

    Args:
        v (jnp.ndarray): The input vector. Has shape (n_tasks, n_features,
            n_partitions*n_cells).
        lam (float): The regularization parameter.

    Returns:
        jnp.ndarray: The projected vector.
    """

    for t in range(v.shape[0]):
        v = v.at[t].set(euclidean_proj_l1ball(v[t] / lam))

    return v


def core_linf1_prox(
    v: jnp.ndarray,
    lam: float,
) -> jnp.ndarray:
    """Compute the linf,1 proximal operator, where the inf norm is computed over
        all cells and tasks together.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).
        lam (float): The regularization parameter.

    Returns:
        jnp.ndarray: The projected vector.
    """
    # (n_t, n_f, n_c*n_p) -> (n_f, n_t * n_c * n_p) and back so that
    # the 1 norm is computed over all cells and tasks. This is easier than trying
    # to compute the proximal operator over a 3D tensor.
    v = jnp.moveaxis(v, 0, 1)
    v_shape = v.shape
    v = v.reshape(v_shape[0], -1)

    v -= lam * euclidean_proj_l1ball(v / lam)

    v = v.reshape(*v_shape)
    return jnp.moveaxis(v, 1, 0)


def core_linf1_norm(
    v: jnp.ndarray,
) -> jnp.ndarray:
    """Compute the linf,1 norm where the inf norm is computed over all cells
        and tasks together.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).

    Returns:
        float: The linf,1 norm.
    """
    return jnp.sum(jnp.max(jnp.abs(v), axis=2), axis=0)


def task_linf1_norm(
    v: jnp.ndarray,
) -> float:
    """Compute the linf,1 norm where the inf norm is computed over all cells and
        tasks together.

    Args:
        v (jnp.ndarray): The input vector, of shape (n_tasks, n_features,
            n_partitions*n_cells).

    Returns:
        float: The linf,1 norm.
    """
    return jnp.max(jnp.abs(v), axis=-1)


class MTJOPLEn:
    def __init__(
        self: MTJOPLEn,
        partitioner: type[Partitioner],
        n_cells: int = 1,
        n_partitions: int = 1,
        random_state: int | RandomState = 0,
        part_kwargs: dict[str, int] | None = None,
        is_regression: bool = True,
    ) -> None:
        """Initialize the JOPLEn object.

        Args:
            self (MTJOPLEn): The JOPLEn object.
            partitioner (type[Partitioner]): The partitioner to use. Should not
                be prefit, unlike the singletask case.
            n_cells (int, optional): The number of cells for each partition of
                the input space. Defaults to 1.
            n_partitions (int, optional): The number of partitions for each
                task. Defaults to 1.
            random_state (int | RandomState, optional): The random state.
                Defaults to 0.
            part_kwargs (dict[str, int] | None, optional): Additional keyword
                arguments for the partitioner. Defaults to None.
            is_regression (bool, optional): Whether the task is a regression
                task. Defaults to True.
        """
        if not issubclass(partitioner, Partitioner):
            raise ValueError("Value of partitioner must be a subclass of Partitioner.")

        if n_cells == 1 and n_partitions > 1:
            raise RuntimeWarning(
                "Multiple partitions with a single cell is redundant and will only increase execution time."
            )

        if n_cells < 1:
            raise ValueError("Number of cells must be greater than 0.")
        if n_partitions < 1:
            raise ValueError("Number of partitions must be greater than 0.")

        self.pclass = partitioner
        self.n_cells = n_cells
        self.n_partitions = n_partitions
        self.partitioners: list[Partitioner] | None = None
        self.cws: list[jnp.ndarray] | None = None
        self.cwb: list[jnp.ndarray] | None = None
        self.x_scalers: list[StandardScaler] | None = None
        self.y_scalers: list[StandardScaler] | None = None
        self.part_kwargs: dict[str, int] | None = part_kwargs or {}
        self.is_regression = is_regression
        self.loss = SquaredError() if is_regression else LogisticLoss()

        if not isinstance(random_state, RandomState):
            self.random_state: RandomState = RandomState(random_state)
        else:
            self.random_state: RandomState = random_state

    def _create_partitioners(
        self: MTJOPLEn,
        lst_x: list[np.ndarray],
        lst_y: list[np.ndarray],
    ) -> list[Partitioner]:
        """Create the partitioners for each round.

        Args:
            self (JOPLEn): The JOPLEn object.
            lst_x (list[np.ndarray]): The input data as a list. Each element of
                the list is a numpy array of shape (n_samples, n_features). They
                do not have to have the same dimensionality
            lst_y (list[np.ndarray]): The input labels in a list. Each element
                has the shape (n_samples,).
        """
        partitioners = []

        for x, y in tqdm(
            zip(lst_x, lst_y),
            total=len(lst_x),
            desc="Partition tasks",
        ):
            partitioners.append(
                self.pclass(
                    x,
                    y,
                    self.n_cells,
                    self.n_partitions,
                    LossType.regression,
                    self.random_state.randint(0, 2**32 - 1),
                    **self.part_kwargs,
                )
            )

        return partitioners

    def _get_cells(
        self: MTJOPLEn,
        x: np.ndarray,
        task_idx: int,
    ) -> jnp.ndarray:
        """Get the partitions for each round.

        Args:
            self (JOPLEn): The JOPLEn object.
            x (jnp.ndarray): The input data, of shape (n_samples, n_features).
            task_idx (int): The index of the task.

        Returns:
            jnp.ndarray: An (n_samples, n_partitions) array of partition indices.
        """
        if self.partitioners is None:
            raise ValueError("Must fit the model before getting partitions.")

        partitioner = self.partitioners[task_idx]
        p_idx = partitioner.partition(x)
        p_idx = p_idx + np.arange(self.n_partitions) * self.n_cells

        binary_mask = np.zeros((x.shape[0], self.n_partitions * self.n_cells))
        binary_mask[np.arange(x.shape[0])[:, None], p_idx] = 1

        return jnp.asarray(binary_mask, dtype=DTYPE)

    def add_bias(self: MTJOPLEn, x: np.ndarray) -> np.ndarray:
        """Add a bias term to the input data.

        Args:
            x (np.ndarray): The input data, of shape (n_samples, n_features).

        Returns:
            np.ndarray: The input data with a bias term, of shape (n_samples,
                n_features + 1).
        """
        return np.hstack((x, np.ones((x.shape[0], 1), dtype=DTYPE)))

    def fit(
        self: MTJOPLEn,
        lst_x: list[np.ndarray],
        lst_y: list[np.ndarray],
        core_lam: float = 0.001,
        task_lam: float = 0.001,
        mu: float = 0.001,
        max_iters: int = 1000,
        print_epochs: int = 100,
        verbose: bool = True,
        lst_val_x: list[np.ndarray] | None = None,
        lst_val_y: list[np.ndarray] | None = None,
        threshold: float = 1e-3,
        norm_type: NormType = NormType.L21,
        core_alpha: float = 0.001,
        task_alpha: float = 0.001,
        rel_lr: Sequence[float] | None = None,
    ) -> dict[str, list[float]]:
        """Fit the JOPLEn model.

        Args:
            self (JOPLEn): The JOPLEn object.
            lst_x (list[np.ndarray]): The input data as a list. Each element of
                the list is a numpy array of shape (n_samples, n_features).
                They do not have to have the same number of samples.
            lst_y (list[np.ndarray]): The input labels, each of size (n_samples,).
            core_lam (float, optional): The l_{2,p}-norm regularization parameter
                for the core weights. Defaults to 0.001.
            task_lam (float, optional): The l_{2,p}-norm regularization parameter
                for the task weights. Defaults to 0.001.
            mu (float, optional): The step size. Defaults to 0.001.
            max_iters (int, optional): The maximum number of iterations.
                Defaults to 1000.
            print_epochs (int, optional): The number of epochs between each
                logging. Defaults to 100.
            verbose (bool, optional): Whether to print the logs. Defaults to
                True.
            lst_val_x (Union[list[np.ndarray], None], optional): The validation
                input data. Only used for reference, not early stopping. Defaults
                to None.
            lst_val_y (Union[list[np.ndarray], None], optional): The validation
                input labels. Only used for reference, not early stopping.
                Defaults to None.
            threshold (float, optional): The threshold for a feature to be
                considered selected. Defaults to 1e-3.
            norm_type (NormType, optional): The type of norm to use when performing
                JOPLEN Dirty LASSO. Defaults to NormType.L21.
            core_alpha (Callable[[jnp.ndarray, float], jnp.ndarray], optional):
                The weight for the F-norm penalty applied to the core weights.
                Defaults to 0.001.
            task_alpha (Callable[[jnp.ndarray, float], jnp.ndarray], optional):
                The weight for the F-norm penalty applied to the task weights.
                Defaults to 0.001.
            rel_lr (Sequence[float] | None, optional): The relative learning rates
                for each task, equivalent to the inverse of a penalty. Defaults
                to None, meaning that the learning rate is the same for all tasks.
        """
        # Rescale/preprocess the data
        lst_x = [numpify(x) for x in lst_x]
        lst_y = [numpify(y) for y in lst_y]

        self.x_scalers = [StandardScaler().fit(x) for x in lst_x]
        self.y_scalers = [StandardScaler().fit(y) for y in lst_y]

        lst_x = [xs.transform(x) for xs, x in zip(self.x_scalers, lst_x)]
        lst_y = [ys.transform(y) for ys, y in zip(self.y_scalers, lst_y)]

        use_val = lst_val_x is not None and lst_val_y is not None

        if use_val:
            lst_val_x = [numpify(x) for x in lst_val_x]
            lst_val_y = [numpify(y) for y in lst_val_y]

            lst_val_x = [xs.transform(x) for xs, x in zip(self.x_scalers, lst_val_x)]
            lst_val_y = [ys.transform(y) for ys, y in zip(self.y_scalers, lst_val_y)]
        else:
            lst_val_x = None
            lst_val_y = None

        # fit the partitioners and cache the partitions
        self.partitioners = self._create_partitioners(lst_x, lst_y)
        lst_s = [self._get_cells(x, i) for i, x in enumerate(lst_x)]

        lst_x_aug = list(map(self.add_bias, lst_x))

        # Move the training data to the GPU
        lst_x_aug = [jnp.asarray(x, dtype=DTYPE) for x in lst_x_aug]
        lst_y = [jnp.asarray(y, dtype=DTYPE) for y in lst_y]

        del lst_x

        if use_val:
            lst_val_s = [self._get_cells(x, i) for i, x in enumerate(lst_val_x)]

            lst_val_x = [jnp.asarray(x, dtype=DTYPE) for x in lst_val_x]
            lst_val_y = [jnp.asarray(y, dtype=DTYPE) for y in lst_val_y]

            lst_val_x = list(map(self.add_bias, lst_val_x))
        else:
            lst_val_s = None

        lst_wb_prev = jnp.zeros(
            (
                len(lst_x_aug),
                lst_x_aug[0].shape[1],
                self.n_partitions * self.n_cells,
            ),
            dtype=DTYPE,
        )
        lst_ws_prev = lst_wb_prev.copy()

        lst_wb_next = lst_wb_prev
        lst_ws_next = lst_ws_prev

        history = defaultdict(list)

        # Reweight the learning rates for each task
        if rel_lr is None:
            sqrt_ds_sizes = [np.sqrt(x.shape[0]) for x in lst_x_aug]
            rel_lr = jnp.asarray(sqrt_ds_sizes, dtype=DTYPE)
        else:
            assert len(rel_lr) == len(
                lst_x_aug
            ), "Must have a learning rate for each task."
            assert all(lr > 0 for lr in rel_lr), "Learning rates must be positive."

            rel_lr = jnp.asarray(rel_lr, dtype=DTYPE)

        rel_lr /= rel_lr.max()

        # set up the proximal operators and norms
        if norm_type == NormType.L21:
            core_prox = core_l21_prox
            task_prox = task_l21_prox
            core_norm = core_l21_norm
            task_norm = task_l21_norm
        elif norm_type == NormType.LINF1:
            core_prox = core_linf1_prox
            task_prox = task_linf1_prox
            core_norm = core_linf1_norm
            task_norm = task_linf1_norm

        t_curr = 1
        t_next = 1

        # proximal gradient descent
        for i in range(max_iters):
            lst_wb_tmp = lst_wb_next
            lst_ws_tmp = lst_ws_next

            t_next = (1 + jnp.sqrt(1 + 4 * t_curr**2)) / 2
            beta = (t_curr - 1) / t_next

            for j in range(len(lst_x_aug)):
                # Perform accelerated gradient descent
                momentum_b = lst_wb_next[j] + beta * (lst_wb_next[j] - lst_wb_prev[j])
                momentum_s = lst_ws_next[j] + beta * (lst_ws_next[j] - lst_ws_prev[j])

                grad = mu * self.loss.grad(
                    momentum_b + momentum_s,
                    lst_x_aug[j],
                    lst_y[j],
                    lst_s[j],
                )

                lst_wb_next = lst_wb_next.at[j].set(lst_wb_next[j] - rel_lr[j] * grad)
                lst_ws_next = lst_ws_next.at[j].set(lst_ws_next[j] - rel_lr[j] * grad)

                if core_alpha > 0:
                    lst_wb_next = lst_wb_next.at[j].set(
                        lst_wb_next[j] - mu * core_alpha * momentum_b
                    )
                if task_alpha > 0:
                    lst_wb_next = lst_wb_next.at[j].set(
                        lst_wb_next[j] - mu * task_alpha * momentum_s
                    )

            # apply proximal operator
            if core_lam > 0:
                lst_wb_next = lst_wb_next.at[:, :-1].set(
                    core_prox(lst_wb_next[:, :-1], mu * core_lam)
                )
            if task_lam > 0:
                lst_ws_next = lst_ws_next.at[:, :-1].set(
                    task_prox(lst_ws_next[:, :-1], mu * task_lam)
                )

            lst_wb_prev = lst_wb_tmp
            lst_ws_prev = lst_ws_tmp

            # logging
            if (i + 1) % print_epochs == 0:
                res = self.record_performance(
                    lst_wb_next,
                    lst_ws_next,
                    lst_x_aug,
                    lst_y,
                    lst_s,
                    i,
                    verbose,
                    lst_val_x,
                    lst_val_y,
                    lst_val_s,
                    threshold,
                    core_norm,
                    task_norm,
                    core_lam,
                    task_lam,
                    core_alpha,
                    task_alpha,
                )

                for k, v in res.items():
                    if v is not None:
                        history[k].append(v)

        self.cwb = lst_wb_next
        self.cws = lst_ws_next

        return dict(history)

    def record_performance(
        self: MTJOPLEn,
        lst_wb_next: jnp.ndarray,
        lst_ws_next: jnp.ndarray,
        lst_x_aug: list[jnp.ndarray],
        lst_y: list[jnp.ndarray],
        lst_s: list[jnp.ndarray],
        i: int,
        verbose: bool,
        lst_val_x: list[jnp.ndarray] | None,
        lst_val_y: list[jnp.ndarray] | None,
        lst_val_s: list[jnp.ndarray] | None,
        threshold: float,
        core_norm: Callable[[jnp.ndarray], float],
        task_norm: Callable[[jnp.ndarray], float],
        core_lam: float,
        task_lam: float,
        core_alpha: float,
        task_alpha: float,
    ) -> dict[str, tuple[float, ...] | float]:
        """Compute the performance metrics and log the results.

        Args:
            self (MTJOPLEn): The JOPLEn object.
            lst_wb_next (jnp.ndarray): A list of the core weights, each of shape
                (n_features+1, n_partitions*n_cells) that will be saved if it's
                the best.
            lst_ws_next (jnp.ndarray): A list of the task weights, each of shape
                (n_features+1, n_partitions*n_cells) that will be saved if it's
                the best.
            lst_x_aug (list[jnp.ndarray]): The input data as a list. Each element
                of the list is a numpy array of shape (n_samples, n_features+1).
                They do not have to have the same number of samples.
            lst_y (list[jnp.ndarray]): The input labels, each of size (n_samples,).
            lst_s (list[jnp.ndarray]): A list of the partition matrices for each
                task. Each element has shape (n_samples, n_partitions*n_cells).
            i (int): The current epoch.
            verbose (bool): Whether the logs should be printed.
            lst_val_x (list[jnp.ndarray] | None): A list containing the validation
                input data, each of shape (n_samples, n_features + 1).
            lst_val_y (list[jnp.ndarray] | None): A list containing the validation
                input labels, each of shape (n_samples,).
            lst_val_s (list[jnp.ndarray] | None): A list of the validation partition
                matrices for each task. Each element has shape (n_samples,
                n_partitions*n_cells).
            threshold (float): The value above which a feature is considered selected.
            core_norm (Callable[[jnp.ndarray], float]): The function used to
                compute the norm of the core weights.
            task_norm (Callable[[jnp.ndarray], float]): The function used to
                compute the norm of the task weights.
            core_lam (float): The weight for the penalty applied to the core weights.
            task_lam (float): The weight for the penalty applied to the task weights.
            core_alpha (float): The F-norm penalty applied to the core weights.
            task_alpha (float): The F-norm penalty applied to the task weights.

        Returns:
            dict[str, tuple[float, ...] | float]: A dictionary containing the
                training loss, validation loss, objective values, the norms of
                the core and task weights, and the features selected by the core
                and task weights.
        """
        tmp_hist = []
        loss_strs = []
        raw_loss = []

        for j in range(len(lst_x_aug)):
            loss_next = self._score(
                lst_wb_next[j] + lst_ws_next[j],
                lst_x_aug[j],
                lst_y[j],
                lst_s[j],
                j,
            )
            raw_loss.append(
                self.loss(
                    lst_wb_next[j] + lst_ws_next[j],
                    lst_x_aug[j],
                    lst_y[j],
                    lst_s[j],
                )
            )

            tmp_hist.append(loss_next)
            loss_strs.append(f"{loss_next:.6f}")

        current_time = datetime.now().strftime("%H:%M:%S")
        report_str = f"[{current_time}]:"

        report_str += f" Epoch {i + 1:>6d} | TrL: {', '.join(loss_strs)}"

        if lst_val_x is not None and lst_val_y is not None:
            tmp_hist_val = []
            val_loss_strs = []
            for j in range(len(lst_val_x)):
                val_loss = self._score(
                    lst_wb_next[j] + lst_ws_next[j],
                    lst_val_x[j],
                    lst_val_y[j],
                    lst_val_s[j],
                    j,
                )
                val_loss_strs.append(f"{val_loss:.6f}")
                tmp_hist_val.append(val_loss)
            report_str += f" | VaL: {', '.join(val_loss_strs)}"
            val_loss = tuple(tmp_hist_val)
        else:
            val_loss = None

        wb_norm = core_norm(lst_wb_next[:, :-1])
        ws_norm = task_norm(lst_ws_next[:, :-1])
        wb_norm_sum = float(wb_norm.sum())
        ws_norm_sum = float(ws_norm.sum())

        report_str += f" | CNorm: {float(wb_norm_sum):.6f}"
        report_str += f" | TNorm: {float(ws_norm_sum):.6f}"

        wb_fnorm = sq_fnorm(lst_wb_next[:, :-1])
        wb_fnorm = sq_fnorm(lst_ws_next[:, :-1])
        report_str += f" | CFNorm: {wb_fnorm:.6f}"
        report_str += f" | TFNorm: {wb_fnorm:.6f}"

        wb_sel_idx = wb_norm > threshold
        ws_sel_idx = ws_norm > threshold
        ws_sel_idx = ws_sel_idx & ~wb_sel_idx
        ws_sel_idx_str = ", ".join([f"{w.sum():>4d}" for w in ws_sel_idx])
        report_str += f" | WbNz: {wb_sel_idx.sum():>4d}"
        report_str += f" | WsNz: {ws_sel_idx_str}"

        b_n_features = float(wb_sel_idx.sum())
        s_n_features = tuple([float(w.sum()) for w in ws_sel_idx])
        train_loss = tuple(tmp_hist)

        # Compensate since all terms are scaled by P for the gradient
        objective = sum(raw_loss)
        objective += core_lam * wb_norm_sum
        objective += task_lam * ws_norm_sum
        objective += core_alpha * wb_fnorm
        objective += task_alpha * wb_fnorm

        if verbose:
            print(report_str)

        return {
            "train_loss": train_loss,
            "raw_loss": raw_loss,
            "val_loss": val_loss,
            "wb_norm": wb_norm_sum,
            "ws_norm": ws_norm_sum,
            "b_n_features": b_n_features,
            "s_n_features": s_n_features,
            "wb_fnorm": wb_fnorm,
            "wb_fnorm": wb_fnorm,
            "objective": objective,
        }

    def _score(
        self: MTJOPLEn,
        w: jnp.ndarray,
        x: jnp.ndarray,
        y_true: jnp.ndarray,
        s: jnp.ndarray,
        task_idx: int,
    ) -> float:
        """Compute the loss function.

        Args:
            self (JOPLEn): The JOPLEn object.
            w (jnp.ndarray): The weight matrix, of shape (n_features+1, n_partitions*n_cells).
            x (jnp.ndarray): The input data, of shape (n_samples, n_features+1).
            y (jnp.ndarray): The input response variables, of shape (n_samples,).
            s (jnp.ndarray): The partition matrix, of shape (n_samples, n_partitions*n_cells).
            task_idx (int): The index of the task being scored.

        Returns:
            float: The loss value.
        """
        y_pred = np.array(self.loss.predict(w, x, s))
        y_pred = self.y_scalers[task_idx].inverse_transform(y_pred)

        y_true = self.y_scalers[task_idx].inverse_transform(np.array(y_true))

        return float(root_mean_squared_error(y_true, y_pred))

    def predict(self: MTJOPLEn, x: jnp.ndarray, task_idx: int) -> np.ndarray:
        """Predict the output for the given input and task.

        Args:
            self (JOPLEn): The JOPLEn object.
            x (jnp.ndarray): The input data, of shape (n_samples, n_features).
            task_idx (int): The index of the task.

        Returns:
            jnp.ndarray: The predicted output.
        """
        if self.cws is None:
            raise NotFittedError("Must fit the model before predicting.")

        x = numpify(x)

        x = self.x_scalers[task_idx].transform(x)
        s = self._get_cells(x, task_idx)

        x_aug = self.add_bias(x)

        x_aug = jnp.asarray(x_aug)

        y_pred = np.array(
            self.loss.predict(
                self.cwb[task_idx] + self.cws[task_idx],
                x_aug,
                s,
            )
        )
        return self.y_scalers[task_idx].inverse_transform(y_pred)


if __name__ == "__main__":
    import time
    from pathlib import Path
    from pprint import pprint

    import pandas as pd
    from lightgbm import LGBMRegressor
    from sklearn.datasets import make_regression

    # Generate synthetic data for multitask regression
    n_samples = 1000
    n_features = 20
    n_tasks = 3
    noise = 0.1

    np.random.seed(0)

    # Generate synthetic data
    x = np.random.randn(n_samples, n_features)
    tmat = np.random.randn(n_features, n_tasks)
    cmat = np.random.randn(n_features, 1)
    cmat = np.tile(cmat, (1, n_tasks))

    tmat[np.abs(tmat) < 1.5] = 0
    cmat[np.abs(cmat) < 1.5] = 0

    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].matshow(cmat)
    axs[1].matshow(tmat)
    plt.show()

    assert cmat.shape == tmat.shape

    w = cmat + tmat  # Generate weight matrix

    noise_vector = noise * np.random.randn(n_samples, n_tasks)  # Generate noise vector

    # Calculate target variable y using matrix multiplication
    y = np.dot(x, w) + noise_vector

    x_train, x_val, x_test = x[:800], x[800:900], x[900:]
    y_train, y_val, y_test = y[:800], y[800:900], y[900:]

    print(x_train.shape, y_train.shape)

    # Tile the input data for multiple tasks
    x_train = np.tile(x_train, (n_tasks, 1, 1))
    x_val = np.tile(x_val, (n_tasks, 1, 1))
    x_test = np.tile(x_test, (n_tasks, 1, 1))

    # Transpose the targets
    y_train = np.transpose(y_train)
    y_val = np.transpose(y_val)
    y_test = np.transpose(y_test)

    n_cells = 2
    n_partitions = 10
    print_epochs = 100
    task_lam = 0.2
    core_lam = 0.2
    mu = 1e-2
    max_iters = 1000
    norm_type = NormType.L21
    core_alpha = 0.0
    task_alpha = 0.0
    rel_lr = [1] * n_tasks

    def rmse(y_true, y_pred):  # noqa: ANN001, ANN201
        return root_mean_squared_error(y_true, y_pred)

    # get current file path
    path = Path().absolute()

    dummy_pred = []
    for _, ytr, _, yte in zip(x_train, y_train, x_test, y_test):
        dummy = np.mean(ytr)
        y_pred = np.full(yte.shape, dummy)
        dummy_pred.append(rmse(yte, y_pred.flatten()))

    print("Dummy")
    print(dummy_pred)

    lgbm_pred = []
    for xtr, ytr, xte, yte in tqdm(
        zip(x_train, y_train, x_test, y_test), total=n_tasks
    ):
        lgbm = LGBMRegressor(verbose=-1, max_depth=3, n_estimators=100)
        lgbm.fit(xtr, ytr.flatten())
        y_pred = lgbm.predict(xte)
        lgbm_pred.append(rmse(yte, y_pred.flatten()))

    print("LGBM")
    print(lgbm_pred)

    jp = MTJOPLEn(
        VPartition,
        n_cells=n_cells,
        n_partitions=n_partitions,
    )

    start_time = time.time()

    history = jp.fit(
        x_train,
        y_train,
        print_epochs=print_epochs,
        core_lam=core_lam,
        task_lam=task_lam,
        mu=mu,
        max_iters=max_iters,
        verbose=True,
        lst_val_x=x_test,
        lst_val_y=y_test,
        norm_type=norm_type,
        core_alpha=core_alpha,
        task_alpha=task_alpha,
        rel_lr=rel_lr,
    )

    end_time = time.time()

    print("Time:", (end_time - start_time))

    print(len(history["b_n_features"]))

    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].plot(history["raw_loss"])
    axs[1].plot(history["ws_norm"])
    axs[2].plot(history["objective"])

    # set titles
    axs[0].set_title("Raw Training Loss")
    axs[1].set_title("Core Norm")
    axs[2].set_title("Objective Function")

    plt.show()

    core_weights = np.array(jp.cwb)[:, :-1]
    task_weights = np.array(jp.cws)[:, :-1]

    n_tasks, n_feats, n_cells = core_weights.shape
    core_weights = core_weights.transpose(1, 0, 2).reshape(n_feats, -1)
    task_weights = task_weights.transpose(1, 0, 2).reshape(n_feats, -1)

    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].matshow(core_weights)
    axs[1].matshow(task_weights)

    axs[0].set_title("Core Weights")
    axs[1].set_title("Task Weights")

    plt.show()

    # get the selected features for each task
    wb_norm = np.linalg.norm(np.array(jp.cwb), axis=(0, 2), ord="fro")[:-1]
    ws_norm = np.linalg.norm(np.array(jp.cws), axis=2, ord=2)[:, :-1]

    wb_sel_idx = wb_norm > 1e-3
    ws_sel_idx = ws_norm > 1e-3
    ws_sel_idx = ws_sel_idx & ~wb_sel_idx

    x_train = [x[:, wb_sel_idx + ws_sel_idx[i]] for i, x in enumerate(x_train)]
    x_test = [x[:, wb_sel_idx + ws_sel_idx[i]] for i, x in enumerate(x_test)]

    masked_pred = []
    for xtr, ytr, xte, yte in zip(x_train, y_train, x_test, y_test):
        lgbm = LGBMRegressor(verbose=-1)
        lgbm.fit(xtr, ytr.flatten())
        y_pred = lgbm.predict(xte)
        masked_pred.append(rmse(yte, y_pred.flatten()))

    # combine into a table using pandas
    print(
        pd.DataFrame(
            {
                "Dummy": dummy_pred,
                "LGBM": lgbm_pred,
                "LGBM via JOPLEn": masked_pred,
            },
        )
    )
